---
layout: post
title: "ì±—GPT APIì™€ ì™¸ë¶€ë„êµ¬ ì—°ê³„"
author: ê¹€íƒœì˜
date: 2023-8-21 00:00:00
categories: ai
comments: true
---

ì´ ë…¸íŠ¸ë¶ì€ GPT ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ í™•ì¥í•˜ê¸° ìœ„í•´ ì™¸ë¶€ í•¨ìˆ˜ì™€ í•¨ê»˜ Chat Completions APIë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤.

`functions`ëŠ” Chat Completion APIì—ì„œ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë§¤ê°œë³€ìˆ˜ë¡œ, í•¨ìˆ˜ ì‚¬ì–‘ì„ ì œê³µí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ì˜ ëª©ì ì€ ì œê³µëœ ì‚¬ì–‘ì„ ì¤€ìˆ˜í•˜ëŠ” í•¨ìˆ˜ ì¸ìˆ˜ë¥¼ ìƒì„±í•˜ë„ë¡ ëª¨ë¸ì„ í™œì„±í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. APIëŠ” ì‹¤ì œë¡œ ì–´ë–¤ í•¨ìˆ˜ í˜¸ì¶œë„ ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê°œë°œìëŠ” ëª¨ë¸ ì¶œë ¥ì„ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ í˜¸ì¶œì„ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

`functions` ë§¤ê°œë³€ìˆ˜ê°€ ì œê³µë˜ë©´ ëª¨ë¸ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì–´ë–¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì •í•˜ê²Œ ë©ë‹ˆë‹¤. `function_call` ë§¤ê°œë³€ìˆ˜ë¥¼ `{"name": "<í•¨ìˆ˜-ì´ë¦„-ì‚½ì…>"}`ë¡œ ì„¤ì •í•¨ìœ¼ë¡œì¨ APIëŠ” íŠ¹ì • í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ê°•ì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ `function_call` ë§¤ê°œë³€ìˆ˜ë¥¼ `"none"`ìœ¼ë¡œ ì„¤ì •í•¨ìœ¼ë¡œì¨ APIëŠ” ì–´ë–¤ í•¨ìˆ˜ë„ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ê°•ì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•¨ìˆ˜ê°€ ì‚¬ìš©ë˜ë©´, ì¶œë ¥ì—ëŠ” ì‘ë‹µì—ì„œ `"finish_reason": "function_call"`ì´ í¬í•¨ë˜ë©°, í•¨ìˆ˜ì˜ ì´ë¦„ê³¼ ìƒì„±ëœ í•¨ìˆ˜ ì¸ìˆ˜ë¥¼ ê°€ì§„ `function_call` ê°ì²´ë„ í¬í•¨ë©ë‹ˆë‹¤.

### ê°œìš”

ì´ ë…¸íŠ¸ë¶ì—ëŠ” ë‹¤ìŒì˜ 2ê°œ ì„¹ì…˜ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

- **í•¨ìˆ˜ ì¸ìˆ˜ ìƒì„±í•˜ëŠ” ë°©ë²•:** ì¼ë ¨ì˜ í•¨ìˆ˜ë¥¼ ì§€ì •í•˜ê³  APIë¥¼ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ ì¸ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- **ëª¨ë¸ì´ ìƒì„±í•œ ì¸ìˆ˜ë¡œ í•¨ìˆ˜ í˜¸ì¶œí•˜ëŠ” ë°©ë²•:** ì‹¤ì œë¡œ ëª¨ë¸ì´ ìƒì„±í•œ ì¸ìˆ˜ë¡œ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•¨ìœ¼ë¡œì¨ ë£¨í”„ë¥¼ ë‹«ìŠµë‹ˆë‹¤.


```python
import os

os.environ["OPENAI_API_KEY"] = "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" # í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
```

## How to generate function arguments

```python
!pip install scipy
!pip install tenacity
!pip install tiktoken
!pip install termcolor
!pip install openai
!pip install requests
```

```
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)
Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.2)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting tiktoken
  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.7/1.7 MB[0m [31m25.8 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)
Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)
Installing collected packages: tiktoken
Successfully installed tiktoken-0.4.0
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (2.3.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting openai
  Downloading openai-0.27.8-py3-none-any.whl (73 kB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m73.6/73.6 kB[0m [31m4.5 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)
Collecting aiohttp (from openai)
  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.0/1.0 MB[0m [31m29.9 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)
Collecting multidict<7.0,>=4.5 (from aiohttp->openai)
  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m114.5/114.5 kB[0m [31m14.4 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)
  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl<2.0,>=1.0 (from aiohttp->openai)
  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m268.8/268.8 kB[0m [31m29.2 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)
  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m149.6/149.6 kB[0m [31m18.0 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai
Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)

```

```python
import json
import openai
import requests
from tenacity import retry, wait_random_exponential, stop_after_attempt
from termcolor import colored

GPT_MODEL = "gpt-3.5-turbo-0613"
openai.api_key = "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" # í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
```

### ìœ í‹¸ë¦¬í‹°

ë¨¼ì € Chat Completions APIì— í˜¸ì¶œì„ í•˜ê¸° ìœ„í•œ ëª‡ ê°€ì§€ ìœ í‹¸ë¦¬í‹°ì™€ ëŒ€í™” ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ì¶”ì í•˜ê¸° ìœ„í•œ ìœ í‹¸ë¦¬í‹°ë¥¼ ì •ì˜í•´ë´…ì‹œë‹¤.

```python
@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))
def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer " + openai.api_key,
    }
    json_data = {"model": model, "messages": messages}
    if functions is not None:
        json_data.update({"functions": functions})
    if function_call is not None:
        json_data.update({"function_call": function_call})
    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=json_data,
        )
        return response
    except Exception as e:
        print("Unable to generate ChatCompletion response")
        print(f"Exception: {e}")
        return e

```

```python
def pretty_print_conversation(messages):
    role_to_color = {
        "system": "red",
        "user": "green",
        "assistant": "blue",
        "function": "magenta",
    }
    formatted_messages = []
    for message in messages:
        if message["role"] == "system":
            formatted_messages.append(f"system: {message['content']}\n")
        elif message["role"] == "user":
            formatted_messages.append(f"user: {message['content']}\n")
        elif message["role"] == "assistant" and message.get("function_call"):
            formatted_messages.append(f"assistant: {message['function_call']}\n")
        elif message["role"] == "assistant" and not message.get("function_call"):
            formatted_messages.append(f"assistant: {message['content']}\n")
        elif message["role"] == "function":
            formatted_messages.append(f"function ({message['name']}): {message['content']}\n")
    for formatted_message in formatted_messages:
        print(
            colored(
                formatted_message,
                role_to_color[messages[formatted_messages.index(formatted_message)]["role"]],
            )
        )
```

### ê¸°ë³¸ ê°œë…

ê°€ìƒì˜ ë‚ ì”¨ APIì™€ ì¸í„°í˜ì´ìŠ¤í•˜ê¸° ìœ„í•œ ëª‡ëª‡ í•¨ìˆ˜ ì‚¬ì–‘ì„ ìƒì„±í•´ë´…ì‹œë‹¤. ì´ëŸ¬í•œ í•¨ìˆ˜ ì‚¬ì–‘ì„ Chat Completions APIì— ì „ë‹¬í•˜ì—¬ ì‚¬ì–‘ì— ë¶€í•©í•˜ëŠ” í•¨ìˆ˜ ì¸ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
functions = [
    {
        "name": "get_current_weather",
        "description": "Get the current weather",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "The city and state, e.g. San Francisco, CA",
                },
                "format": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "The temperature unit to use. Infer this from the users location.",
                },
            },
            "required": ["location", "format"],
        },
    },
    {
        "name": "get_n_day_weather_forecast",
        "description": "Get an N-day weather forecast",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "The city and state, e.g. San Francisco, CA",
                },
                "format": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "The temperature unit to use. Infer this from the users location.",
                },
                "num_days": {
                    "type": "integer",
                    "description": "The number of days to forecast",
                }
            },
            "required": ["location", "format", "num_days"]
        },
    },
]
```

ë§Œì•½ ìš°ë¦¬ê°€ ëª¨ë¸ì—ê²Œ í˜„ì¬ ë‚ ì”¨ì— ëŒ€í•´ ë¬¼ì–´ë³¸ë‹¤ë©´, ëª¨ë¸ì€ ëª‡ ê°€ì§€ êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì‘ë‹µí•  ê²ƒì…ë‹ˆë‹¤.

```python
messages = []
messages.append({"role": "system", "content": "Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous."})
messages.append({"role": "user", "content": "What's the weather like today"})
chat_response = chat_completion_request(
    messages, functions=functions
)
assistant_message = chat_response.json()["choices"][0]["message"]
messages.append(assistant_message)
assistant_message

```

ìš°ë¦¬ê°€ ëˆ„ë½ëœ ì •ë³´ë¥¼ ì œê³µí•˜ë©´, ëª¨ë¸ì€ ìš°ë¦¬ë¥¼ ìœ„í•´ ì ì ˆí•œ í•¨ìˆ˜ ì¸ìˆ˜ë¥¼ ìƒì„±í•´ì¤„ ê²ƒì…ë‹ˆë‹¤.

```python
messages.append({"role": "user", "content": "I'm in Glasgow, Scotland."})
chat_response = chat_completion_request(
    messages, functions=functions
)
assistant_message = chat_response.json()["choices"][0]["message"]
messages.append(assistant_message)
assistant_message

```

ë‹¤ë¥´ê²Œ í”„ë¡¬í”„íŠ¸í•˜ë©´, ìš°ë¦¬ê°€ ì•Œë ¤ì¤€ ë‹¤ë¥¸ í•¨ìˆ˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
messages = []
messages.append({"role": "system", "content": "Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous."})
messages.append({"role": "user", "content": "what is the weather going to be like in Glasgow, Scotland over the next x days"})
chat_response = chat_completion_request(
    messages, functions=functions
)
assistant_message = chat_response.json()["choices"][0]["message"]
messages.append(assistant_message)
assistant_message

```

ë‹¤ì‹œ í•œë²ˆ, ëª¨ë¸ì€ ì•„ì§ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ê°–ê³  ìˆì§€ ì•Šê¸° ë•Œë¬¸ì— ìš°ë¦¬ì—ê²Œ êµ¬ì²´í™”ë¥¼ ìš”ì²­í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì—ëŠ” ì´ë¯¸ ì˜ˆë³´ë¥¼ ìœ„í•œ ìœ„ì¹˜ë¥¼ ì•Œê³  ìˆì§€ë§Œ, ì˜ˆë³´ì— í•„ìš”í•œ ì¼ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ë˜ëŠ”ì§€ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.

```python
messages.append({"role": "user", "content": "5 days"})
chat_response = chat_completion_request(
    messages, functions=functions
)
chat_response.json()["choices"][0]

```

#### íŠ¹ì • í•¨ìˆ˜ì˜ ì‚¬ìš© ê°•ì œ ë˜ëŠ” í•¨ìˆ˜ ì‚¬ìš© ì•ˆ í•¨

ìš°ë¦¬ëŠ” `function_call` ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í•¨ìˆ˜, ì˜ˆë¥¼ ë“¤ë©´ `get_n_day_weather_forecast`ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ëª¨ë¸ì—ê²Œ ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´, ëª¨ë¸ì€ ê·¸ê²ƒì„ ì–´ë–»ê²Œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ê°€ì •ì„ í•˜ê²Œ ë©ë‹ˆë‹¤.

```python
# in this cell we force the model to use get_n_day_weather_forecast
messages = []
messages.append({"role": "system", "content": "Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous."})
messages.append({"role": "user", "content": "Give me a weather report for Toronto, Canada."})
chat_response = chat_completion_request(
    messages, functions=functions, function_call={"name": "get_n_day_weather_forecast"}
)
chat_response.json()["choices"][0]["message"]

```

```python
# if we don't force the model to use get_n_day_weather_forecast it may not
messages = []
messages.append({"role": "system", "content": "Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous."})
messages.append({"role": "user", "content": "Give me a weather report for Toronto, Canada."})
chat_response = chat_completion_request(
    messages, functions=functions
)
chat_response.json()["choices"][0]["message"]

```

ëª¨ë¸ì—ê²Œ ì•„ì˜ˆ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ê°•ì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì´ ì ì ˆí•œ í•¨ìˆ˜ í˜¸ì¶œì„ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.

```python
messages = []
messages.append({"role": "system", "content": "Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous."})
messages.append({"role": "user", "content": "Give me the current weather (use Celcius) for Toronto, Canada."})
chat_response = chat_completion_request(
    messages, functions=functions, function_call="none"
)
chat_response.json()["choices"][0]["message"]

```

## ëª¨ë¸ì´ ìƒì„±í•œ ì¸ìˆ˜ë¡œ í•¨ìˆ˜ í˜¸ì¶œí•˜ëŠ” ë°©ë²•

ë‹¤ìŒ ì˜ˆì œì—ì„œëŠ” ëª¨ë¸ì´ ìƒì„±í•œ ì…ë ¥ì„ ê°€ì§„ í•¨ìˆ˜ë¥¼ ì–´ë–»ê²Œ ì‹¤í–‰í•˜ëŠ”ì§€ ë³´ì—¬ì¤„ ê²ƒì´ë©°, ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ê´€í•œ ì§ˆë¬¸ì— ëŒ€ë‹µí•  ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ [Chinook ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤](https://www.sqlitetutorial.net/sqlite-sample-database/)ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.

*ì£¼ì˜:* SQL ìƒì„±ì€ ìƒì‚° í™˜ê²½ì—ì„œ ë†’ì€ ìœ„í—˜ì„ ìˆ˜ë°˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ë“¤ì€ ì˜¬ë°”ë¥¸ SQLì„ ìƒì„±í•˜ëŠ” ë° ì™„ë²½í•˜ê²Œ ë¯¿ì„ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

### SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì§€ì •

ë¨¼ì € SQLite ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
import sqlite3

conn = sqlite3.connect("Chinook.db")
print("Opened database successfully")
```

```
ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì—´ì—ˆìŠµë‹ˆë‹¤.

```

```python
def get_table_names(conn):
    """Return a list of table names."""
    table_names = []
    tables = conn.execute("SELECT name FROM sqlite_master WHERE type='table';")
    for table in tables.fetchall():
        table_names.append(table[0])
    return table_names


def get_column_names(conn, table_name):
    """Return a list of column names."""
    column_names = []
    columns = conn.execute(f"PRAGMA table_info('{table_name}');").fetchall()
    for col in columns:
        column_names.append(col[1])
    return column_names


def get_database_info(conn):
    """Return a list of dicts containing the table name and columns for each table in the database."""
    table_dicts = []
    for table_name in get_table_names(conn):
        columns_names = get_column_names(conn, table_name)
        table_dicts.append({"table_name": table_name, "column_names": columns_names})
    return table_dicts

```

ì´ì œ ì´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì˜ í‘œí˜„ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
database_schema_dict = get_database_info(conn)
database_schema_string = "\n".join(
    [
        f"Table: {table['table_name']}\nColumns: {', '.join(table['column_names'])}"
        for table in database_schema_dict
    ]
)
```

ì´ì „ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, APIì—ê²Œ ì¸ìˆ˜ë¥¼ ìƒì„±í•˜ë„ë¡ ì›í•˜ëŠ” í•¨ìˆ˜ì— ëŒ€í•œ í•¨ìˆ˜ ì‚¬ì–‘ì„ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ í•¨ìˆ˜ ì‚¬ì–‘ì— ì‚½ì…í•œë‹¤ëŠ” ì ì— ì£¼ëª©í•˜ì„¸ìš”. ì´ê²ƒì€ ëª¨ë¸ì´ ì•Œì•„ì•¼ í•  ì¤‘ìš”í•œ ì •ë³´ì…ë‹ˆë‹¤.

```python
functions = [
    {
        "name": "ask_database",
        "description": "Use this function to answer user questions about music. Output should be a fully formed SQL query.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": f"""
                            SQL query extracting info to answer the user's question.
                            SQL should be written using this database schema:
                            {database_schema_string}
                            The query should be returned in plain text, not in JSON.
                            """,
                }
            },
            "required": ["query"],
        },
    }
]
```

### SQL ì¿¼ë¦¬ ì‹¤í–‰

ì´ì œ ë°ì´í„°ë² ì´ìŠ¤ì— ì¿¼ë¦¬ë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•  í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ë´…ì‹œë‹¤.

```python
def ask_database(conn, query):
    """Function to query SQLite database with a provided SQL query."""
    try:
        results = str(conn.execute(query).fetchall())
    except Exception as e:
        results = f"query failed with error: {e}"
    return results

def execute_function_call(message):
    if message["function_call"]["name"] == "ask_database":
        query = json.loads(message["function_call"]["arguments"])["query"]
        results = ask_database(conn, query)
    else:
        results = f"Error: function {message['function_call']['name']} does not exist"
    return results
```

```python
messages = []
messages.append({"role": "system", "content": "Answer user questions by generating SQL queries against the Chinook Music Database."})
messages.append({"role": "user", "content": "Hi, who are the top 5 artists by number of tracks?"})
chat_response = chat_completion_request(messages, functions)
assistant_message = chat_response.json()["choices"][0]["message"]
messages.append(assistant_message)
if assistant_message.get("function_call"):
    results = execute_function_call(assistant_message)
    messages.append({"role": "function", "name": assistant_message["function_call"]["name"], "content": results})
pretty_print_conversation(messages)
```

```
system: Answer user questions by generating SQL queries against the Chinook Music Database.

user: Hi, who are the top 5 artists by number of tracks?

assistant: {'name': 'ask_database', 'arguments': '{\n  "query": "SELECT Artist.Name, COUNT(*) AS TrackCount FROM Artist INNER JOIN Album ON Artist.ArtistId = Album.ArtistId INNER JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.ArtistId ORDER BY TrackCount DESC LIMIT 5"\n}'}

function (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]


```

```python
messages.append({"role": "user", "content": "What is the name of the album with the most tracks?"})
chat_response = chat_completion_request(messages, functions)
assistant_message = chat_response.json()["choices"][0]["message"]
messages.append(assistant_message)
if assistant_message.get("function_call"):
    results = execute_function_call(assistant_message)
    messages.append({"role": "function", "content": results, "name": assistant_message["function_call"]["name"]})
pretty_print_conversation(messages)
```

### ì¶œì²˜

* https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb
