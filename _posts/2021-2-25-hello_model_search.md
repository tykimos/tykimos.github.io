---
layout: post
title:  "ì½”ë©ì—ì„œ êµ¬ê¸€ ëª¨ë¸ ì„œì¹˜ êµ¬ë™í•˜ê¸°"
author: ê¹€íƒœì˜
date:   2021-2-25 13:00:00
categories: python
comments: true
image: http://tykimos.github.io/warehouse/2021-2-25-hello_model_search_title_1.png
---
êµ¬ê¸€ ëª¨ë¸ ì„œì¹˜ëŠ” ê¸°ì¡´ NAS(ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ íƒìƒ‰)ì˜ ë‹¨ì ì„ ë³´ì•ˆí•˜ê³ , íš¨ìœ¨ì ì´ê³  ìë™ìœ¼ë¡œ ìµœì ì˜ ëª¨ë¸ì„ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì œê³µë˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ê¸€ ëª¨ë¸ ì„œì¹˜ë¥¼ ì½”ë©ì—ì„œ ë°”ë¡œ êµ¬ë™í•´ë³¼ ìˆ˜ ìˆë„ë¡ í…ŒìŠ¤íŠ¸í•œ ê²°ê³¼ë¥¼ ê³µìœ í•©ë‹ˆë‹¤. ê¹ƒí—™ ì„¤ì¹˜ë¶€í„° íŒ¨í‚¤ì§€ ì„¤ì¹˜, í™˜ê²½ ì„¤ì •, ì˜ˆì œ ì†ŒìŠ¤ ì½”ë“œ ì„¤ëª… ê·¸ë¦¬ê³  ì¶œë ¥ê°’ì„ í™•ì¸í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 

### ê´€ë ¨ ì •ë³´
---

*   ë¸”ë¡œê·¸ ì£¼ì†Œ: https://ai.googleblog.com/2021/02/introducing-model-search-open-source.html
*   ê¹ƒí—™ ì£¼ì†Œ: https://github.com/google/model_search



<a href="https://colab.research.google.com/github/tykimos/hello-ai/blob/main/hello_model_search.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

### í™˜ê²½ì„¤ì •
---

ë¨¼ì € ê¹ƒí—™ì—ì„œ ì†ŒìŠ¤ì½”ë“œ ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤.


```python
!git clone https://github.com/google/model_search.git
```

    Cloning into 'model_search'...
    remote: Enumerating objects: 141, done.[K
    remote: Counting objects: 100% (141/141), done.[K
    remote: Compressing objects: 100% (109/109), done.[K
    remote: Total 141 (delta 30), reused 136 (delta 28), pack-reused 0[K
    Receiving objects: 100% (141/141), 214.12 KiB | 3.02 MiB/s, done.
    Resolving deltas: 100% (30/30), done.


"model_search" í´ë” ì•ˆìœ¼ë¡œ í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤. 


```python
%cd model_search
```

    /content/model_search


íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ë¥¼ ìœ„í•´ì„œ ì•„ë˜ ëª…ë ¹ì„ í†µí•´ ë¯¸ë¦¬ ì •ì˜í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.


```python
!pip install -r requirements.txt
```

    Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.15.0)
    Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.0)
    Collecting tensorflow==2.2.0
    [?25l  Downloading https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 516.2MB 16kB/s 
    [?25hRequirement already satisfied: absl-py==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.10.0)
...
    Installing collected packages: tensorflow-estimator, tensorboard, tensorflow, tf-slim, ml-metadata, terminaltables, colorama, keras-tuner, mock
      Found existing installation: tensorflow-estimator 2.4.0
        Uninstalling tensorflow-estimator-2.4.0:
          Successfully uninstalled tensorflow-estimator-2.4.0
      Found existing installation: tensorboard 2.4.1
        Uninstalling tensorboard-2.4.1:
          Successfully uninstalled tensorboard-2.4.1
      Found existing installation: tensorflow 2.4.1
        Uninstalling tensorflow-2.4.1:
          Successfully uninstalled tensorflow-2.4.1
    Successfully installed colorama-0.4.4 keras-tuner-1.0.2 ml-metadata-0.26.0 mock-4.0.3 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0 terminaltables-3.1.0 tf-slim-1.1.0


ë¯¸ë¦¬ ì •ì˜í•œ êµ¬ê¸€ í”„ë¡œí† ì½œ ë²„í¼ íŒŒì¼(ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” í•˜ë‚˜ì˜ ë°©ì‹)ì„ íŒŒì´ì¬ ì½”ë“œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.


```python
!protoc --python_out=./ model_search/proto/hparam.proto
!protoc --python_out=./ model_search/proto/phoenix_spec.proto
!protoc --python_out=./ model_search/proto/distillation_spec.proto
!protoc --python_out=./ model_search/proto/ensembling_spec.proto
!protoc --python_out=./ model_search/proto/transfer_learning_spec.proto
```

ì½”ë© ì‹¤í–‰ ì‹œì— ëª…ë ¹ ì¸ì í•´ì„ ì˜¤ë¥˜ê°€ ì¼ì–´ë‚˜ì§€ ì•Šë„ë¡ ëª…ë ¹ ì¸ì ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.


```python
import sys
from absl import app

sys.argv = sys.argv[:1]

try:
  app.run(lambda argv: None)
except:
  pass
```

### ì‹œì‘í•˜ê¸°
---

ë¸”ë¡œê·¸ì— ë‚˜ì™€ìˆëŠ” ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì£¼ìš” ì¸ì ìœ„ì£¼ë¡œ ì‚´í´ë³´ë©´,

* number_models=200
    * 200ê°œ ëª¨ë¸ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.
* root_dir="/tmp/run_example"
    * ê²€ìƒ‰í•œ ëª¨ë¸ í‰ê°€ ê²°ê³¼ë¥¼ ë‹´ê³  ìˆëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. í…ì„œë³´ë“œì—ì„œ ì—´ ìˆ˜ ìˆìœ¼ë©°, í‰ê°€ë©”íŠ¸ë¦­ê³¼ í•¨ê»˜ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* logits_dimension=2
    * ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì„ íƒìƒ‰í•©ë‹ˆë‹¤.
* filename="model_search/data/testdata/csv_random_data.csv"
    * ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
* spec="model_search/configs/dnn_config.pbtxt"
    * ëª¨ë¸ íƒìƒ‰ì„ ìœ„í•œ ìŠ¤í™ì´ ì •ì˜ëœ íŒŒì¼ì„ ì§€ì •í•©ë‹ˆë‹¤.


```python
import model_search
from model_search import constants
from model_search import single_trainer
from model_search.data import csv_data

trainer = single_trainer.SingleTrainer(
    data=csv_data.Provider(
        label_index=0,
        logits_dimension=2,
        record_defaults=[0, 0, 0, 0],
        filename="model_search/data/testdata/csv_random_data.csv"),
        spec="model_search/configs/dnn_config.pbtxt")

trainer.try_models(
    number_models=200,
    train_steps=1000,
    eval_steps=100,
    root_dir="/tmp/run_example",
    batch_size=32,
    experiment_name="example",
    experiment_owner="model_search_user")
```

    [0m
    I0225 06:13:21.385653 139685296322432 estimator.py:2066] Saving dict for global step 1111: accuracy = 1.0, auc_pr = 1.0, auc_roc = 0.9999998, global_step = 1111, loss = 0.0, num_parameters = 218394
    I0225 06:13:21.672063 139685296322432 estimator.py:2127] Saving 'checkpoint_path' summary for global step 1111: /tmp/run_example/tuner-1/130/model.ckpt-1111
    I0225 06:13:21.676702 139685296322432 phoenix.py:123] Saving the following evaluation dictionary.
    I0225 06:13:21.683635 139685296322432 phoenix.py:124] {'accuracy': 1.0, 'auc_pr': 1.0, 'auc_roc': 0.9999998211860657, 'loss': 0.0, 'num_parameters': 218394, 'global_step': 1111}
    I0225 06:13:21.688025 139685296322432 ml_metadata_db.py:156] Storing the following evaluation dictionary,
    I0225 06:13:21.689974 139685296322432 ml_metadata_db.py:157] {'accuracy': 1.0, 'auc_pr': 1.0, 'auc_roc': 0.9999998211860657, 'loss': 0.0, 'num_parameters': 218394, 'global_step': 1111}
    I0225 06:13:21.691386 139685296322432 ml_metadata_db.py:158] For the model in the following model dictionary,
    I0225 06:13:21.694412 139685296322432 ml_metadata_db.py:159] /tmp/run_example/tuner-1/130
    I0225 06:13:21.723419 139685296322432 oss_trainer_lib.py:256] Evaluation results: {'accuracy': 1.0, 'auc_pr': 1.0, 'auc_roc': 0.9999998, 'loss': 0.0, 'num_parameters': 218394, 'global_step': 1111}
    I0225 06:13:24.253669 139685296322432 oss_trainer_lib.py:281] creating directory: /tmp/run_example/tuner-1/131
    I0225 06:13:24.255254 139685296322432 oss_trainer_lib.py:328] Tuner id: tuner-1
    I0225 06:13:24.268173 139685296322432 oss_trainer_lib.py:329] Training with the following hyperparameters: 
    I0225 06:13:24.269536 139685296322432 oss_trainer_lib.py:330] {'learning_rate': 0.01, 'new_block_type': 'FIXED_OUTPUT_FULLY_CONNECTED_256', 'optimizer': 'momentum', 'initial_architecture_0': 'FIXED_OUTPUT_FULLY_CONNECTED_128', 'exponential_decay_rate': 0.75, 'exponential_decay_steps': 250, 'gradient_max_norm': 5, 'dropout_rate': 0.5500000216066837, 'initial_architecture': ['FIXED_OUTPUT_FULLY_CONNECTED_128']}
    I0225 06:13:24.280349 139685296322432 run_config.py:550] TF_CONFIG environment variable: {'model_dir': '/tmp/run_example/tuner-1/131', 'session_master': ''}
    I0225 06:13:24.281677 139685296322432 run_config.py:973] Using model_dir in TF_CONFIG: /tmp/run_example/tuner-1/131
    I0225 06:13:24.284329 139685296322432 estimator.py:191] Using config: {'_model_dir': '/tmp/run_example/tuner-1/131', '_tf_random_seed': None, '_save_summary_steps': 2000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 120, '_session_config': allow_soft_placement: true
    graph_options {
      rewrite_options {
        meta_optimizer_iterations: ONE
      }
    }
    ...
    I0225 06:33:46.598200 139685296322432 base_tower_generator.py:112] Building from existing checkpoint.
    I0225 06:33:47.663316 139685296322432 estimator.py:1171] Done calling model_fn.
    I0225 06:33:47.701185 139685296322432 evaluation.py:255] Starting evaluation at 2021-02-25T06:33:47Z
    I0225 06:33:47.878722 139685296322432 monitored_session.py:246] Graph was finalized.
    I0225 06:33:47.883833 139685296322432 saver.py:1293] Restoring parameters from /tmp/run_example/tuner-1/200/model.ckpt-1111
    I0225 06:33:48.062550 139685296322432 session_manager.py:505] Running local_init_op.
    I0225 06:33:48.119457 139685296322432 session_manager.py:508] Done running local_init_op.
    I0225 06:33:48.513041 139685296322432 evaluation.py:273] Inference Time : 0.81043s
    I0225 06:33:48.514187 139685296322432 evaluation.py:276] Finished evaluation at 2021-02-25-06:33:48
    I0225 06:33:48.516498 139685296322432 estimator.py:2066] Saving dict for global step 1111: accuracy = 1.0, auc_pr = 1.0, auc_roc = 0.9999998, global_step = 1111, loss = 0.0, num_parameters = 73783
    I0225 06:33:48.789884 139685296322432 estimator.py:2127] Saving 'checkpoint_path' summary for global step 1111: /tmp/run_example/tuner-1/200/model.ckpt-1111
    I0225 06:33:48.792447 139685296322432 phoenix.py:123] Saving the following evaluation dictionary.
    I0225 06:33:48.794008 139685296322432 phoenix.py:124] {'accuracy': 1.0, 'auc_pr': 1.0, 'auc_roc': 0.9999998211860657, 'loss': 0.0, 'num_parameters': 73783, 'global_step': 1111}
    I0225 06:33:48.795351 139685296322432 ml_metadata_db.py:156] Storing the following evaluation dictionary,
    I0225 06:33:48.796216 139685296322432 ml_metadata_db.py:157] {'accuracy': 1.0, 'auc_pr': 1.0, 'auc_roc': 0.9999998211860657, 'loss': 0.0, 'num_parameters': 73783, 'global_step': 1111}
    I0225 06:33:48.797077 139685296322432 ml_metadata_db.py:158] For the model in the following model dictionary,
    I0225 06:33:48.797994 139685296322432 ml_metadata_db.py:159] /tmp/run_example/tuner-1/200
    I0225 06:33:48.815671 139685296322432 oss_trainer_lib.py:256] Evaluation results: {'accuracy': 1.0, 'auc_pr': 1.0, 'auc_roc': 0.9999998, 'loss': 0.0, 'num_parameters': 73783, 'global_step': 1111}
    I0225 06:33:48.829422 139685296322432 oss_trainer_lib.py:281] creating directory: /tmp/run_example/tuner-1/201


### ë§ˆë¬´ë¦¬
---

êµ¬ê¸€ ëª¨ë¸ ì„œì¹˜ë¥¼ ì½”ë©ì—ì„œ êµ¬ë™í•˜ê¸° ìœ„í•œ í™˜ê²½ì„¤ì • ë° ì†ŒìŠ¤ì½”ë“œ ì˜ˆì œë¥¼ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒì—ëŠ” ëª¨ë¸ ì„œì¹˜ ê²°ê³¼ í™•ì¸ ë° í™œìš© ë°©ì•ˆì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.
