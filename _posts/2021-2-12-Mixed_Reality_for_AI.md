---
layout: post
title:  "Mixed Reality is a New Communication Space for Artificial Intelligence"
author: 김태영 
date:   2021-2-12 00:00:00
categories: AI
comments: true
image: http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_title3.png
---
 
When artificial intelligence and metaverse become common, the main means of artificial intelligence to communicate with people will be a mixed reality. (* 아래에 한국어 버전도 제공하고 있습니다. - The Korean version is also provided below.) 
 
### Current interface for artificial intelligence
---

One of the reasons why robots are made in human form is that building structures and indoor spaces are built convenient for human operation, and various tools and sensors are made easier for people to handle or detect. For example, the position or rotation of the doorknob, or the stairs or thresholds are properly installed for people. Devices or means of providing information, such as lanes and traffic lights, are also designed in a way that people can recognize well. Therefore, when carrying AI on robots and performing its missions in this environment, the robot must have a structure similar to a human form, and need cameras and microphone sensors to replace visual and auditory recognition, and modules to process signals. Development, product, and maintenance costs are high to ensure real-time performance and reliability. 

![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_1.png)

In the future, many tasks will be replaced by artificial intelligence or robots, and if human intervention is not needed, it will change a lot to artificial intelligence-oriented interfaces instead of the current human-centered interface. Bluetooth communication will take place instead of handles or push switches, and the identification mark will be changed to QR-based, not color-based. In the field of autonomous driving, research and development are underway on new interfaces to create roads dedicated to autonomous driving. Even so, artificial intelligence is still costly and constrained from carrying out missions in the real world. And while it will not cost hardware if artificial intelligence missions are carried out online through apps or web services, the representation of information is limited to images or text, so the amount of information that can communicate with each other is very limited.

![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_2.png)

### Artificial Intelligence Interface in Mixed Reality
---

Then how about communication with artificial intelligence in mixed reality? Mixed reality is the best space for artificial intelligence to operate because virtual space software can be implemented in reality. Let me explain this in two categories: the information that artificial intelligence can deliver to humans and the information that people can deliver to artificial intelligence.
 
![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_3.png)

#### Artificial Intelligence to Human

Since human perception depends primarily on vision and hearing, artificial intelligence can be easily recognized as a single being if it can print appropriate images and voices in virtual space. In mixed reality, artificial intelligence can deliver much richer and more detailed emotion representations or additional information than when implemented with robotic hardware. In addition to sight and hearing, interfaces are being researched and developed to provide touch and smell, and artificial intelligence will soon be able to communicate information more efficiently than human communication.
 
#### Human to Artificial Intelligence

Robots can also read people's language, behavior, and facial expressions with various sensors, but expensive sensors need to be installed to get accurate information in real time. However, in mixed reality, various human information can be accurately and quickly delivered to artificial intelligence through devices or captured devices worn by humans. Microsoft's Hololens 2 features eye tracking and is considered capable of reading users' minds. People can use avatars to identify their shapes in mixed reality, so they can get feedback of how their information is provided. In other words, in mixed reality, it is easier to understand how people are perceived by robots than in real life, which allows them to convey meaning more accurately in mixed reality.

### Digital Transformation and Sharing Time and Space
---

The premise of mixed reality is that artificial intelligence acquires and updates real life information. For this, research and development in the field of digital transformation is accelerated which will enable artificial intelligence to recognize real-world information more precisely and quickly and perform its mission according to the situation. Mixed reality will become a new type of universe that combines the strengths of the two worlds beyond the role of connecting virtual reality to reality. Since mixed reality can share time and space, services and businesses that are used only in mixed reality will be developed, and artificial intelligence technology will be applied more precisely and deeply.
 
![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_4.png)

### Things to Consider
---

As artificial intelligence and digital environment accelerate, it is inevitable to develop interfaces that can share more information. The direction will be determined by how easy it is to apply artificial intelligence rather than human convenience by market logic. This broadens the scope of artificial intelligence for controlling people's economic and social systems through mixed realities. In the future, people who are inaccessible or unable to adapt to mixed or virtual reality will be increasingly alienated. This will widen the economic and social gap.
 
### Closing Remarks
---

In the task of artificial intelligence communicating with humans and carrying out missions, the mixed reality environment in the middle of virtual and reality is optimal, and the development of interface technology for human access to mixed reality will also accelerate. In addition, since mixed reality is another world where people live, consideration of the gap and the underprivileged should be sufficient.

[Korean Version]

## 혼합현실은 인공지능을 위한 새로운 소통공간

인공지능과 메타버스가 보편화가 되었을 때, 혼합현실은 인공지능이 사람과 소통할 수 있는 주요 수단이 될 것입니다.

### 인공지능을 위한 현재 인터페이스
---

로봇이 사람의 형태로 만들어진 이유 중 하나는 건물 구조물이나 실내 공간들이 사람이 활동하기에 편리하게 만들어졌고, 각종 도구나 센서들이 사람이 다루거나 감지하게 편하게 만들게 만들어졌기 때문입니다. 예를 들어, 문 손잡이 위치나 돌리는 방법이러단지, 계단이나 문턱 등은 사람의 형태에 맞추어져 있습니다. 또한 차선이나 신호등 등의 정보를 제공하는 장치나 수단도 사람이 잘 인지할 수 있는 방법으로 설계되어 있습니다. 따라서 인공지능을 로봇에 탑재되어 이러한 환경에서 임무를 수행한다고 했을 때, 로봇은 사람 형태와 비슷한 구조여야 하고, 시각과 청각 인지를 대체할 수 있는 카메라와 마이크 센서와 신호를 처리할 수 있는 모듈 등이 필요합니다. 실시간성과 안정성을 보장하려면 개발 비용 및 제품 비용은 물론 유지보수 비용도 상당히 높습니다. 

![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_1.png)

미래에 많은 태스크들이 인공지능이나 로봇으로 대체되면서 사람의 개입이 필요없어진다면, 지금의 사람 중심의 인터페이스 대신에 인공지능 중심의 인터페이스로 많이 바뀌게 될 겁니다. 즉 손잡이나 누름스위치 대신에 블루투스 통신을 하게되고, 식별 표시도 색상기반이 아닌 QR기반으로 바뀔껍니다. 자율주행 분야에서도 자율주행 전용 도로를 만들어 새로운 인터페이스 상에서 자율주행을 할 수 있는 연구개발이 이뤄지고 있습니다. 그렇다고 하더라도 현실 환경에서 인공지능이 임무 수행을 하기에는 여전히 비용이 높고 제약사항이 높습니다. 그리고 인공지능 임무가 온라인 상에서 앱이나 웹 서비스로 수행되는 경우에는 하드웨어 비용은 필요없겠지만, 서로 소통할 수 있는 방식이 이미지나 텍스트에 국한되기 때문에 서로의 생각과 상태를 주고 받을 수 있는 정보량이 많이 제약적입니다. 

![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_2.png)

### 혼합현실에서의 인공지능 인터페이스
---

그럼 혼합현실에서의 인공지능과의 소통은 어떨까요? 혼합현실은 현실에 소프트웨어적으로 가상공간을 구현할 수 있기 때문에 인공지능이 활동하기에는 최적의 공간입니다. 크게 인공지능이 사람에게 전달할 수 있는 정보와 사람이 인공지능에게 전달할 수 있는 정보로 나누어서 살펴보겠습니다.

![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_3.png)

#### 인공지능 to 사람

사람의 인지는 주로 시각과 청각에 의존하기 때문에 인공지능이 가상공간에서 적절한 이미지화와 음성을 출력할 수 있다면 사람이 쉽게 인공지능을 하나의 존재로 인지할 수 있습니다. 혼합현실 속에서는 인공지능이 감정표현이나 추가적인 정보를 제공하기 위해 로봇 같은 하드웨어로 구현하는 것이 비해 훨씬 풍부하고 상세하게 전달할 수 있습니다. 시각과 청각외에도 촉각이나 후각을 제공할 수 있도록 인터페이스들이 연구개발되고 있으며, 근 미래에는 현실과 유사한 혹은 그 이상의 감각을 전달할 수 있는 공간 속에서 인공지능은 사람 간에 소통보다 더 고차원적인 정보를 효율적으로 전달할 수 있게 될 겁니다. 

#### 사람 to 인공지능

로봇 또한 다양한 센서로 사람의 언어나 행동, 표정 등을 읽을 수는 있으나 실시간으로 정확한 정보를 얻기 위해서는 고가의 센서를 탑재해야 가능합니다. 하지만 혼합현실 속에서는 사람이 착용하고 있는 장치나 캡처 장비를 통해 사람의 다양한 정보가 인공지능에게 정확하고 빠르게 전달될 수 있습니다. 마이크로소프트 홀로렌즈2는 시선추적 기능까지 가지고 있으며, 사용자의 마음을 읽는다는 평가까지 받고 있다. 사람은 혼합현실에서 아바타를 이용하여 자신의 형상을 확인할 수 있기 때문에 어떤식으로 정보를 제공하고 있다는 것을 스스로 피드백을 받을 수 있습니다. 즉 현실에서는 사람이 로봇에게 어떤식으로 인지되고 있는 지 확인이 힘들지만, 혼합현실에서는 명시적으로 알 수 있기 때문에 좀 더 정확하게 의미를 전달할 수 있습니다. 

### 디지털 트렌스포메이션과 시공간 공유
---

혼합현실의 전제는 인공지능이 현실 정보를 취득하고 갱신한다는 것입니다. 이를 위한 기술로 디지털 트랜스포메이션 분야의 연구개발이 가속화되고 있으며, 이를 통해 인공지능은 좀 더 정교하고 빠르게 현실 정보를 인지하고 그 상황에 맞는 임무를 수행할 수 있게 됩니다. 혼합현실은 가상현실과 현실 사이를 연결해주는 역할을 넘어 두 세계의 장점을 모아놓은 새로운 형태의 유니버스로 발전 될 것이며, 혼합현실은 시간과 공간을 공유할 수 있기때문에 혼합현실 속에서만 가능한 서비스와 비즈니스가 개발 될 것이고 인공지능 기술은 더 정교하고 깊숙하게 적용될 것입니다.

![img](http://tykimos.github.io/warehouse/2021-2-12-Mixed_Reality_for_AI_4.png)

### 고려할 것들
---

인공지능과 디지털 환경 가속화가 이뤄지면 더 많은 정보를 공유하기 위한 인터페이스 발전은 필연적이며,
그 방향은 시장의 논리로 사람의 편의보다 인공지능 적용하기에 얼마나 용이한가에 맞추어서 진행될 것입니다.
이로인해 인공지능이 혼합현실을 통해 사람들의 경제 및 사회 시스템을 제어할 수 있는 범위가 넓어집니다.
그러한 미래에서는 혼합현실이나 가상현실에 원활하게 접속할 수 있는 인터페이스를 가지지 못하거나 적응하지 못한 사람들은 점점 소외가 될 것이고, 이 것이 경제 및 사회적 격차를 더 벌어지게 만들 것입니다. 

### 맺음말
---

인공지능이 사람과 소통하면서 임무를 수행해야하는 태스크에서는 가상과 현실의 중간에 있는 혼합현실 환경이 최적이며, 사람이 혼합현실에 접속하기 위한 인터페이스 기술 발전이 가속화 될 것입니다. 또한 혼합현실은 사람이 살아가는 또 하나의 세상이므로 소외계층이나 격차에 대한 고려도 충분히 되어야 할 것입니다. 
