{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution1D, Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import callbacks\n",
    "\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class printbatch(callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "#        if batch%10 == 0:\n",
    "            print \"Batch \" + str(batch) + \" ends\"\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        print(logs)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myGenerator():\n",
    "    \n",
    "    # Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "    # X_train, X_test: uint8 array of grayscale image data with shape (nb_samples, 28, 28).\n",
    "    # y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (nb_samples,).\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # ((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))\n",
    "    \n",
    "    y_train = np_utils.to_categorical(y_train,10)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    count = 0\n",
    "    while 1:\n",
    "        for i in range(20): # 1875 * 32 = 60000 -> # of training samples            \n",
    "            print('i:' + str(i) + ' count:' + str(count))\n",
    "            count = count + 1\n",
    "            print('i*32:' + str(i*32) + '  (i+1)*32:' + str((i+1)*32))\n",
    "            yield X_train[i*32:(i+1)*32], y_train[i*32:(i+1)*32] # 32만큼 전달한다.\n",
    "        print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(1, img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Epoch 1/2\n",
      "i:0 count:0\n",
      "i*32:0  (i+1)*32:32\n",
      "i:1 count:1\n",
      "i*32:32  (i+1)*32:64\n",
      "Batch 0 ends\n",
      " 32/640 [>.............................] - ETA: 113s - loss: 2.3230i:2 count:2\n",
      "i*32:64  (i+1)*32:96\n",
      "Batch 1 ends\n",
      " 64/640 [==>...........................] - ETA: 55s - loss: 2.6246 i:3 count:3\n",
      "i*32:96  (i+1)*32:128\n",
      "Batch 2 ends\n",
      " 96/640 [===>..........................] - ETA: 35s - loss: 2.4158i:4 count:4\n",
      "i*32:128  (i+1)*32:160\n",
      "Batch 3 ends\n",
      "128/640 [=====>........................] - ETA: 25s - loss: 2.2867i:5 count:5\n",
      "i*32:160  (i+1)*32:192\n",
      "Batch 4 ends\n",
      "160/640 [======>.......................] - ETA: 19s - loss: 2.2367i:6 count:6\n",
      "i*32:192  (i+1)*32:224\n",
      "Batch 5 ends\n",
      "192/640 [========>.....................] - ETA: 15s - loss: 2.1590i:7 count:7\n",
      "i*32:224  (i+1)*32:256\n",
      "Batch 6 ends\n",
      "224/640 [=========>....................] - ETA: 13s - loss: 2.0816i:8 count:8\n",
      "i*32:256  (i+1)*32:288\n",
      "Batch 7 ends\n",
      "256/640 [===========>..................] - ETA: 10s - loss: 2.0420i:9 count:9\n",
      "i*32:288  (i+1)*32:320\n",
      "Batch 8 ends\n",
      "288/640 [============>.................] - ETA: 9s - loss: 1.9805 i:10 count:10\n",
      "i*32:320  (i+1)*32:352\n",
      "Batch 9 ends\n",
      "320/640 [==============>...............] - ETA: 7s - loss: 1.8932i:11 count:11\n",
      "i*32:352  (i+1)*32:384\n",
      "Batch 10 ends\n",
      "352/640 [===============>..............] - ETA: 6s - loss: 1.8462i:12 count:12\n",
      "i*32:384  (i+1)*32:416\n",
      "Batch 11 ends\n",
      "384/640 [=================>............] - ETA: 5s - loss: 1.7940i:13 count:13\n",
      "i*32:416  (i+1)*32:448\n",
      "Batch 12 ends\n",
      "416/640 [==================>...........] - ETA: 4s - loss: 1.7357i:14 count:14\n",
      "i*32:448  (i+1)*32:480\n",
      "Batch 13 ends\n",
      "448/640 [====================>.........] - ETA: 3s - loss: 1.6798i:15 count:15\n",
      "i*32:480  (i+1)*32:512\n",
      "Batch 14 ends\n",
      "480/640 [=====================>........] - ETA: 2s - loss: 1.6283i:16 count:16\n",
      "i*32:512  (i+1)*32:544\n",
      "Batch 15 ends\n",
      "512/640 [=======================>......] - ETA: 2s - loss: 1.6150i:17 count:17\n",
      "i*32:544  (i+1)*32:576\n",
      "Batch 16 ends\n",
      "544/640 [========================>.....] - ETA: 1s - loss: 1.5912i:18 count:18\n",
      "i*32:576  (i+1)*32:608\n",
      "Batch 17 ends\n",
      "576/640 [==========================>...] - ETA: 1s - loss: 1.5638i:19 count:19\n",
      "i*32:608  (i+1)*32:640\n",
      "Batch 18 ends\n",
      "608/640 [===========================>..] - ETA: 0s - loss: 1.5413-------\n",
      "i:0 count:20\n",
      "i*32:0  (i+1)*32:32\n",
      "Batch 19 ends\n",
      "{'loss': 1.5302972942590714}\n",
      "640/640 [==============================] - 10s - loss: 1.5303    \n",
      "{}\n",
      "Epoch 2/2\n",
      "i:1 count:21\n",
      "i*32:32  (i+1)*32:64\n",
      "Batch 0 ends\n",
      " 32/640 [>.............................] - ETA: 4s - loss: 0.9186i:2 count:22\n",
      "i*32:64  (i+1)*32:96\n",
      "Batch 1 ends\n",
      " 64/640 [==>...........................] - ETA: 4s - loss: 0.9412i:3 count:23\n",
      "i*32:96  (i+1)*32:128\n",
      "Batch 2 ends\n",
      " 96/640 [===>..........................] - ETA: 4s - loss: 0.7858i:4 count:24\n",
      "i*32:128  (i+1)*32:160\n",
      "Batch 3 ends\n",
      "128/640 [=====>........................] - ETA: 4s - loss: 0.6875i:5 count:25\n",
      "i*32:160  (i+1)*32:192\n",
      "Batch 4 ends\n",
      "160/640 [======>.......................] - ETA: 3s - loss: 0.7489i:6 count:26\n",
      "i*32:192  (i+1)*32:224\n",
      "Batch 5 ends\n",
      "192/640 [========>.....................] - ETA: 3s - loss: 0.7380i:7 count:27\n",
      "i*32:224  (i+1)*32:256\n",
      "Batch 6 ends\n",
      "224/640 [=========>....................] - ETA: 3s - loss: 0.7056i:8 count:28\n",
      "i*32:256  (i+1)*32:288\n",
      "Batch 7 ends\n",
      "256/640 [===========>..................] - ETA: 3s - loss: 0.7033i:9 count:29\n",
      "i*32:288  (i+1)*32:320\n",
      "Batch 8 ends\n",
      "288/640 [============>.................] - ETA: 3s - loss: 0.7113i:10 count:30\n",
      "i*32:320  (i+1)*32:352\n",
      "Batch 9 ends\n",
      "320/640 [==============>...............] - ETA: 2s - loss: 0.6745i:11 count:31\n",
      "i*32:352  (i+1)*32:384\n",
      "Batch 10 ends\n",
      "352/640 [===============>..............] - ETA: 2s - loss: 0.6663i:12 count:32\n",
      "i*32:384  (i+1)*32:416\n",
      "Batch 11 ends\n",
      "384/640 [=================>............] - ETA: 2s - loss: 0.6569i:13 count:33\n",
      "i*32:416  (i+1)*32:448\n",
      "Batch 12 ends\n",
      "416/640 [==================>...........] - ETA: 2s - loss: 0.6486i:14 count:34\n",
      "i*32:448  (i+1)*32:480\n",
      "Batch 13 ends\n",
      "448/640 [====================>.........] - ETA: 2s - loss: 0.6427i:15 count:35\n",
      "i*32:480  (i+1)*32:512\n",
      "Batch 14 ends\n",
      "480/640 [=====================>........] - ETA: 1s - loss: 0.6149i:16 count:36\n",
      "i*32:512  (i+1)*32:544\n",
      "Batch 15 ends\n",
      "512/640 [=======================>......] - ETA: 1s - loss: 0.6573i:17 count:37\n",
      "i*32:544  (i+1)*32:576\n",
      "Batch 16 ends\n",
      "544/640 [========================>.....] - ETA: 1s - loss: 0.6685i:18 count:38\n",
      "i*32:576  (i+1)*32:608\n",
      "Batch 17 ends\n",
      "576/640 [==========================>...] - ETA: 0s - loss: 0.6626i:19 count:39\n",
      "i*32:608  (i+1)*32:640\n",
      "Batch 18 ends\n",
      "608/640 [===========================>..] - ETA: 0s - loss: 0.6639-------\n",
      "i:0 count:40\n",
      "i*32:0  (i+1)*32:32\n",
      "Batch 19 ends\n",
      "{'loss': 0.67123709693551059}\n",
      "640/640 [==============================] - 7s - loss: 0.6712     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tykimos/Projects/insdeep_tb/venv/lib/python2.7/site-packages/keras/models.py:634: UserWarning: The \"nb_worker\" argument is deprecated, please remove it from your code.\n",
      "  warnings.warn('The \"nb_worker\" argument is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10c6b9550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb = printbatch()\n",
    "\n",
    "model.fit_generator(myGenerator(), \n",
    "                    #samples_per_epoch = 60000, \n",
    "                    samples_per_epoch = 640,                     \n",
    "                    nb_epoch = 2, \n",
    "                    verbose=1, \n",
    "                    callbacks=[pb], \n",
    "                    validation_data=None, \n",
    "                    class_weight=None, \n",
    "                    max_q_size = 1,\n",
    "                    nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
