{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"컨볼루션 신경망 모델을 위한 데이터 부풀리기\"\n",
    "author: 김태영\n",
    "date:   2017-03-08 23:10:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_combination.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컨볼루션 신경망 모델의 성능을 높이기 위한 방법 중 하나인 데이터 부풀리기에 대해서 알아보겠습니다. 훈련셋이 부족하거나 훈련셋이 시험셋의 특성을 충분히 반영하지 못할 때 이 방법을 사용하면 모델의 성능을 크게 향상시킬 수 있습니다. 케라스에서는 데이터 부풀리기를 위한 함수를 제공하기 때문에 파라미터 셋팅만으로 간단히 데이터 부풀리기를 할 수 있습니다.\n",
    "\n",
    "1. 현실적인 문제\n",
    "1. 기존 모델 결과보기\n",
    "1. 데이터 부풀리기\n",
    "1. 개선 모델 결과보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 현실적인 문제\n",
    "\n",
    "앞서 [컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/2017/03/08/CNN_Getting_Started/)에서 사용하였던 원, 사각형, 삼각형 데이터셋을 예제로 살펴보겠습니다. 구성은 훈련셋과 시험셋으로 되어 있는 데, 아래 그림은 훈련셋입니다.\n",
    "\n",
    "#### 훈련셋\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_1.png)\n",
    "\n",
    "그리고 아래 그림은 시험셋입니다. 훈련셋과 시험셋은 모두 한사람(제가) 그린 것이라 거의 비슷합니다. 그래서 그런지 100% 정확도의 좋은 결과를 얻었나 봅니다.\n",
    "\n",
    "#### 시험셋\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_2.png)\n",
    "\n",
    "100% 정확도를 얻은 모델이니 원, 사각형, 삼각형을 그려주면 다 분류를 해보겠다며 지인에게 자랑을 해봅니다. 그래서 지인이 그려준 시험셋은 다음과 같습니다.\n",
    "\n",
    "#### 도전 시험셋\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_3.png)\n",
    "\n",
    "막상 시험셋을 받아보니 자신감이 없어지면서 여러가지 생각이 듭니다.\n",
    "\n",
    "- 아, 이것도 원, 사각형, 삼각형이구나\n",
    "- 왜 이런 데이터를 진작에 학습시키지 않았을까?\n",
    "- 새로 받은 시험셋 일부를 학습시켜볼까?\n",
    "- 이렇게 간단한 문제도 개발과 현실과의 차이가 이렇게 나는데, 실제 문제는 더 상황이 좋지 않겠지?\n",
    "\n",
    "결국 하나의 결론에 도달합니다.\n",
    "\n",
    "    개발자가 시험셋을 만들면 안된다.\n",
    "\n",
    "하지만 어떠한 문제에서도 미래에 들어올 데이터에 대해서는 알 수가 없기 때문에 비슷한 상황에 부딪히는 분들이 많을 것입니다. 먼저 도전 시험셋으로 시험한 결과를 살펴본 뒤, 한정적인 훈련셋을 이용하여 최대한 발생할 수 있는 경우을 고려하여 훈련셋을 만드는 방법인 `데이터 부풀리기`에 대해서 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 기존 모델 결과보기\n",
    "\n",
    "[컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/2017/03/08/CNN_Getting_Started/)에서 사용했던 모델을 그대로 가지고 왔습니다. 제가 만든 시험셋('warehouse/handwriting_shape/test')에서는 결과가 100%나왔는데, 도전 시험셋('warehouse/hard_handwriting_shape/test')으론 어떤 결과가 나오는 지 테스트해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 0s - loss: 0.8350 - acc: 0.5778 - val_loss: 1.8721 - val_acc: 0.3333\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s - loss: 0.1013 - acc: 1.0000 - val_loss: 4.3315 - val_acc: 0.2667\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s - loss: 0.0054 - acc: 1.0000 - val_loss: 4.6139 - val_acc: 0.4000\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 4.2412 - val_acc: 0.4000\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s - loss: 4.3154e-04 - acc: 1.0000 - val_loss: 4.7102 - val_acc: 0.4000\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s - loss: 2.4263e-04 - acc: 1.0000 - val_loss: 5.5255 - val_acc: 0.4000\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s - loss: 2.0701e-04 - acc: 1.0000 - val_loss: 5.6390 - val_acc: 0.3333\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s - loss: 1.6805e-04 - acc: 1.0000 - val_loss: 4.5685 - val_acc: 0.4000\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s - loss: 1.5318e-04 - acc: 1.0000 - val_loss: 6.5609 - val_acc: 0.4667\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s - loss: 1.2832e-04 - acc: 1.0000 - val_loss: 6.7823 - val_acc: 0.2667\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s - loss: 1.1298e-04 - acc: 1.0000 - val_loss: 7.2100 - val_acc: 0.1333\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s - loss: 9.8824e-05 - acc: 1.0000 - val_loss: 5.6343 - val_acc: 0.2667\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s - loss: 8.8855e-05 - acc: 1.0000 - val_loss: 6.4116 - val_acc: 0.4000\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s - loss: 8.2919e-05 - acc: 1.0000 - val_loss: 5.9208 - val_acc: 0.3333\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s - loss: 7.2874e-05 - acc: 1.0000 - val_loss: 5.5624 - val_acc: 0.4667\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s - loss: 6.6589e-05 - acc: 1.0000 - val_loss: 7.0975 - val_acc: 0.2667\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s - loss: 6.1017e-05 - acc: 1.0000 - val_loss: 3.5248 - val_acc: 0.4667\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s - loss: 5.6155e-05 - acc: 1.0000 - val_loss: 6.9998 - val_acc: 0.2667\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s - loss: 5.1274e-05 - acc: 1.0000 - val_loss: 4.3880 - val_acc: 0.3333\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s - loss: 4.7663e-05 - acc: 1.0000 - val_loss: 6.2044 - val_acc: 0.3333\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s - loss: 4.4210e-05 - acc: 1.0000 - val_loss: 5.5105 - val_acc: 0.4000\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s - loss: 4.2834e-05 - acc: 1.0000 - val_loss: 7.5547 - val_acc: 0.2667\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s - loss: 3.8286e-05 - acc: 1.0000 - val_loss: 6.1768 - val_acc: 0.3333\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s - loss: 3.5768e-05 - acc: 1.0000 - val_loss: 6.2004 - val_acc: 0.3333\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s - loss: 3.3293e-05 - acc: 1.0000 - val_loss: 6.9589 - val_acc: 0.3333\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s - loss: 3.0837e-05 - acc: 1.0000 - val_loss: 6.7479 - val_acc: 0.3333\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s - loss: 2.9245e-05 - acc: 1.0000 - val_loss: 5.9912 - val_acc: 0.4000\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s - loss: 2.7418e-05 - acc: 1.0000 - val_loss: 7.1677 - val_acc: 0.3333\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s - loss: 2.5606e-05 - acc: 1.0000 - val_loss: 5.9599 - val_acc: 0.4000\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s - loss: 2.4480e-05 - acc: 1.0000 - val_loss: 7.7355 - val_acc: 0.2667\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s - loss: 2.2945e-05 - acc: 1.0000 - val_loss: 6.3253 - val_acc: 0.3333\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s - loss: 2.1517e-05 - acc: 1.0000 - val_loss: 7.9884 - val_acc: 0.2000\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s - loss: 2.0286e-05 - acc: 1.0000 - val_loss: 6.3504 - val_acc: 0.3333\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s - loss: 1.9265e-05 - acc: 1.0000 - val_loss: 6.3639 - val_acc: 0.3333\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s - loss: 1.8301e-05 - acc: 1.0000 - val_loss: 4.3841 - val_acc: 0.4000\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s - loss: 1.7409e-05 - acc: 1.0000 - val_loss: 5.1816 - val_acc: 0.4667\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s - loss: 1.6494e-05 - acc: 1.0000 - val_loss: 6.4068 - val_acc: 0.3333\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s - loss: 1.5613e-05 - acc: 1.0000 - val_loss: 8.7850 - val_acc: 0.2000\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s - loss: 1.4927e-05 - acc: 1.0000 - val_loss: 6.4126 - val_acc: 0.2667\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s - loss: 1.4196e-05 - acc: 1.0000 - val_loss: 6.4510 - val_acc: 0.3333\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s - loss: 1.3564e-05 - acc: 1.0000 - val_loss: 8.2816 - val_acc: 0.2667\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s - loss: 1.2983e-05 - acc: 1.0000 - val_loss: 7.5257 - val_acc: 0.2667\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s - loss: 1.2369e-05 - acc: 1.0000 - val_loss: 7.1357 - val_acc: 0.2667\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s - loss: 1.1842e-05 - acc: 1.0000 - val_loss: 5.6120 - val_acc: 0.3333\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s - loss: 1.1185e-05 - acc: 1.0000 - val_loss: 6.4721 - val_acc: 0.3333\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s - loss: 1.0697e-05 - acc: 1.0000 - val_loss: 5.4524 - val_acc: 0.4667\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s - loss: 1.0273e-05 - acc: 1.0000 - val_loss: 3.9091 - val_acc: 0.4667\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s - loss: 9.8985e-06 - acc: 1.0000 - val_loss: 6.5501 - val_acc: 0.3333\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s - loss: 9.4150e-06 - acc: 1.0000 - val_loss: 6.4482 - val_acc: 0.4000\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s - loss: 9.0243e-06 - acc: 1.0000 - val_loss: 6.5722 - val_acc: 0.4000\n",
      "-- Evaluate --\n",
      "acc: 33.33%\n",
      "-- Predict --\n",
      "{'circle': 0, 'triangle': 2, 'rectangle': 1}\n",
      "[[0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.005 0.995]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.191 0.053 0.756]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.308 0.008 0.685]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.010 0.990]\n",
      " [0.000 0.000 1.000]]\n"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터 생성하기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/test',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15,\n",
    "        epochs=50,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 정확도는 100%에 가깝지만 시험셋의 평가결과는 33.3%입니다. 세 개 중 하나를 맞추는 문제에서 33.3%의 정확도는 사실상 의미없는 분류 모델입니다. 이 모델은 훈련셋에서만 결과가 좋은 오버피팅 된 모델이라고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 데이터 부풀리기\n",
    "\n",
    "케라스에서는 `ImageDataGenerator` 함수를 통해서 데이터 부풀리기 기능을 제공합니다. [keras.io](https://keras.io/preprocessing/image/#imagedatagenerator) 페이지를 보면, 아래와 같은 옵션으로 데이터 부풀리기를 할 수 있습니다.\n",
    "\n",
    "    keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=K.image_data_format())\n",
    "\n",
    "그럼 훈련셋 중 하나인 삼각형을 골라 데이터 부풀리기를 해보겠습니다. 원본이 되는 삼각형은 다음과 같습니다.\n",
    "\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_4.png)\n",
    "\n",
    "이 삼각형을 ImageDataGenerator 함수을 이용하여 각 파라미터별로 어떻게 부풀리기를 하는 지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rotation_range = 90\n",
    "지정된 각도 범위내에서 임의로 원본이미지를 회전시킵니다. 단위는 도이며, 정수형입니다. 예를 들어 90이라면 0도에서 90도 사이에 임의의 각도로 회전시킵니다.\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_rotate.png)\n",
    "                                   \n",
    "#### width_shift_range = 0.1\n",
    "지정된 수평방향 이동 범위내에서 임의로 원본이미지를 이동시킵니다. 수치는 전체 넓이의 비율(실수)로 나타냅니다. 예를 들어 0.1이고 전체 넓이가 100이면, 10픽셀 내외로 좌우 이동시킵니다.\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_width_shift.png)\n",
    "\n",
    "#### height_shift_range = 0.1\n",
    "지정된 수직방향 이동 범위내에서 임의로 원본이미지를 이동시킵니다. 수치는 전체 높이의 비율(실수)로 나타냅니다. 예를 들어 0.1이고 전체 높이가 100이면, 10픽셀 내외로 상하 이동시킵니다.\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_height_shift.png)\n",
    "\n",
    "#### shear_range = 0.5\n",
    "밀림 강도 범위내에서 임의로 원본이미지를 변형시킵니다. 수치는 시계반대방향으로 밀림 강도를 라디안으로 나타냅니다. 예를 들어 0.5이라면, 0.5 라이안내외로 시계반대방향으로 변형시킵니다.\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_shear.png)\n",
    "\n",
    "#### zoom_range = 0.3\n",
    "지정된 확대/축소 범위내에서 임의로 원본이미지를 확대/축소합니다. \"1-수치\"부터 \"1+수치\"사이 범위로 확대/축소를 합니다. 예를 들어 0.3이라면, 0.7배에서 1.3배 크기 변화를 시킵니다.\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_zoom.png)\n",
    "\n",
    "#### horizontal_flip = True\n",
    "수평방향으로 뒤집기를 합니다.\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_horizontal_flip.png)\n",
    "\n",
    "#### vertical_flip = True\n",
    "수직방향으로 뒤집기를 합니다.\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_vertical_flip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 ImageDataGenerator함수를 이용하여 지정된 파라미터로 원본이미지에 대해 데이터 부풀리기를 수행한 후 그 결과를 특정 폴더에 저장하는 코드입니다. 여러 파라미터를 사용하였기 때문에 이를 혼합하여 데이터 부풀리기를 수행합니다. 즉 확대/축소도 하고 좌우 이동도 지정하였다면, 축소하면서 좌로 이동된 이미지도 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "\n",
    "# 데이터셋 생성하기\n",
    "data_aug_gen = ImageDataGenerator(rescale=1./255, \n",
    "                                  rotation_range=10,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.7,\n",
    "                                  zoom_range=[0.9, 2.2],\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "                                   \n",
    "img = load_img('warehouse/hard_handwriting_shape/train/triangle/triangle001.png')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.\n",
    "for batch in train_datagen.flow(x, batch_size=1, save_to_dir='warehouse/preview', save_prefix='tri', save_format='png'):\n",
    "    i += 1\n",
    "    if i > 30: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드로 데이터 부풀리기가 수행된 결과 이미지는 다음과 같습니다. 지인이 만든 도전 시험셋 중 비슷한 것들도 보입니다.\n",
    "\n",
    "![data](http://tykimos.github.io/warehouse/2017-3-8-CNN_Data_Augmentation_5_combination.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 개선 모델 결과보기\n",
    "\n",
    "데이터 부풀리기를 하기 위해서는 기존 코드에서 아래 코드를 추가합니다. 각 파라미터 설정 값에 따라 결과가 다르기 나오니, 실제 데이터에 있을만한 수준으로 적정값을 지정하셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.7,\n",
    "                                   zoom_range=[0.9, 2.2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수정된 전체 코드는 다음과 같습니다. 참고로 시험셋은 데이터 부풀리기를 할 필요가 없으니, test_datagen 객체 생성 시에는 별도의 파라미터를 추가하지 않았습니다. 그리고 fit_generator함수에서 steps_per_epoch의 값은 기존 15개에서 더 많은 수 (현재 예는 1500개)로 설정합니다. batch_size * steps_per_epoch가 전체 샘플 수 인데, 데이터 부풀리기를 하지 않을 때는 기존의 15개의 배치사이즈(3개)로 전체 45개를 모두 학습에 사용할 수 있지만, ImageDataGenerator함수를 통해 데이터 부풀리기는 할 때는 하나의 샘플로 여러 개의 결과를 얻기 때문에 요청하는 데로 무한의 샘플이 제공됩니다. 여기서는 100배 정도인 1500개로 설정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.4165 - acc: 0.8276 - val_loss: 1.6372 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.1578 - acc: 0.9453 - val_loss: 2.0338 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.1037 - acc: 0.9631 - val_loss: 2.2277 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0867 - acc: 0.9724 - val_loss: 2.2804 - val_acc: 0.7333\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0698 - acc: 0.9762 - val_loss: 2.0338 - val_acc: 0.8000\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0472 - acc: 0.9833 - val_loss: 2.2892 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0683 - acc: 0.9764 - val_loss: 1.8691 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0539 - acc: 0.9827 - val_loss: 1.4486 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0488 - acc: 0.9858 - val_loss: 2.2366 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0399 - acc: 0.9887 - val_loss: 0.9035 - val_acc: 0.8000\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0405 - acc: 0.9882 - val_loss: 1.7024 - val_acc: 0.8667\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0370 - acc: 0.9878 - val_loss: 1.7040 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0328 - acc: 0.9902 - val_loss: 1.3661 - val_acc: 0.8000\n",
      "Epoch 14/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0319 - acc: 0.9898 - val_loss: 2.9003 - val_acc: 0.6667\n",
      "Epoch 15/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0329 - acc: 0.9909 - val_loss: 1.2296 - val_acc: 0.6667\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0333 - acc: 0.9891 - val_loss: 3.0349 - val_acc: 0.6000\n",
      "Epoch 17/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0315 - acc: 0.9911 - val_loss: 1.7367 - val_acc: 0.7333\n",
      "Epoch 18/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0303 - acc: 0.9920 - val_loss: 1.4350 - val_acc: 0.8000\n",
      "Epoch 19/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0290 - acc: 0.9929 - val_loss: 1.5824 - val_acc: 0.8000\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0289 - acc: 0.9909 - val_loss: 1.6781 - val_acc: 0.8000\n",
      "Epoch 21/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0262 - acc: 0.9907 - val_loss: 2.6198 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0411 - acc: 0.9884 - val_loss: 1.3874 - val_acc: 0.8000\n",
      "Epoch 23/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0217 - acc: 0.9929 - val_loss: 4.7283 - val_acc: 0.6000\n",
      "Epoch 24/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0207 - acc: 0.9924 - val_loss: 3.5575 - val_acc: 0.6667\n",
      "Epoch 25/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0227 - acc: 0.9931 - val_loss: 2.4000 - val_acc: 0.7333\n",
      "Epoch 26/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0298 - acc: 0.9924 - val_loss: 4.0425 - val_acc: 0.6000\n",
      "Epoch 27/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0326 - acc: 0.9902 - val_loss: 3.1818 - val_acc: 0.6667\n",
      "Epoch 28/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0291 - acc: 0.9916 - val_loss: 0.8603 - val_acc: 0.9333\n",
      "Epoch 29/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0285 - acc: 0.9927 - val_loss: 2.0220 - val_acc: 0.7333\n",
      "Epoch 30/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0232 - acc: 0.9936 - val_loss: 3.3095 - val_acc: 0.6667\n",
      "Epoch 31/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0328 - acc: 0.9911 - val_loss: 2.8491 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0201 - acc: 0.9947 - val_loss: 3.4662 - val_acc: 0.6667\n",
      "Epoch 33/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0286 - acc: 0.9909 - val_loss: 3.4343 - val_acc: 0.6667\n",
      "Epoch 34/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0222 - acc: 0.9931 - val_loss: 2.1944 - val_acc: 0.8667\n",
      "Epoch 35/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0279 - acc: 0.9927 - val_loss: 2.7526 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0171 - acc: 0.9947 - val_loss: 2.3027 - val_acc: 0.8000\n",
      "Epoch 37/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0281 - acc: 0.9916 - val_loss: 3.2875 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0256 - acc: 0.9933 - val_loss: 0.5803 - val_acc: 0.9333\n",
      "Epoch 39/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0241 - acc: 0.9940 - val_loss: 2.1087 - val_acc: 0.8667\n",
      "Epoch 40/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0230 - acc: 0.9940 - val_loss: 5.2854 - val_acc: 0.5333\n",
      "Epoch 41/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0144 - acc: 0.9956 - val_loss: 2.2295 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0261 - acc: 0.9936 - val_loss: 2.3929 - val_acc: 0.6667\n",
      "Epoch 43/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0115 - acc: 0.9958 - val_loss: 3.2245 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0270 - acc: 0.9933 - val_loss: 2.3790 - val_acc: 0.8000\n",
      "Epoch 45/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0179 - acc: 0.9951 - val_loss: 2.5716 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0265 - acc: 0.9938 - val_loss: 2.3645 - val_acc: 0.8000\n",
      "Epoch 47/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0234 - acc: 0.9922 - val_loss: 2.2298 - val_acc: 0.8000\n",
      "Epoch 48/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0218 - acc: 0.9947 - val_loss: 5.8202 - val_acc: 0.6000\n",
      "Epoch 49/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0237 - acc: 0.9951 - val_loss: 3.6545 - val_acc: 0.7333\n",
      "Epoch 50/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0211 - acc: 0.9949 - val_loss: 1.6513 - val_acc: 0.8667\n",
      "Epoch 51/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0205 - acc: 0.9944 - val_loss: 1.1842 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0114 - acc: 0.9962 - val_loss: 3.4039 - val_acc: 0.7333\n",
      "Epoch 53/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0301 - acc: 0.9920 - val_loss: 2.6281 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0221 - acc: 0.9938 - val_loss: 3.0707 - val_acc: 0.7333\n",
      "Epoch 55/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0165 - acc: 0.9944 - val_loss: 1.6281 - val_acc: 0.8667\n",
      "Epoch 56/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0174 - acc: 0.9953 - val_loss: 2.6185 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0183 - acc: 0.9958 - val_loss: 2.5988 - val_acc: 0.8000\n",
      "Epoch 58/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0147 - acc: 0.9953 - val_loss: 2.4952 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0238 - acc: 0.9929 - val_loss: 2.1652 - val_acc: 0.8667\n",
      "Epoch 60/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0146 - acc: 0.9956 - val_loss: 4.4955 - val_acc: 0.6667\n",
      "Epoch 61/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0149 - acc: 0.9953 - val_loss: 0.4963 - val_acc: 0.9333\n",
      "Epoch 62/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0171 - acc: 0.9953 - val_loss: 2.9639 - val_acc: 0.7333\n",
      "Epoch 63/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0256 - acc: 0.9936 - val_loss: 3.9262 - val_acc: 0.7333\n",
      "Epoch 64/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0171 - acc: 0.9942 - val_loss: 2.6182 - val_acc: 0.8000\n",
      "Epoch 65/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0037 - acc: 0.9984 - val_loss: 2.7017 - val_acc: 0.8000\n",
      "Epoch 66/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0244 - acc: 0.9940 - val_loss: 3.0518 - val_acc: 0.7333\n",
      "Epoch 67/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0125 - acc: 0.9956 - val_loss: 5.0617 - val_acc: 0.6667\n",
      "Epoch 68/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0181 - acc: 0.9958 - val_loss: 2.5997 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0134 - acc: 0.9967 - val_loss: 3.8583 - val_acc: 0.6667\n",
      "Epoch 70/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0177 - acc: 0.9951 - val_loss: 3.2356 - val_acc: 0.8000\n",
      "Epoch 71/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0151 - acc: 0.9964 - val_loss: 3.7206 - val_acc: 0.6667\n",
      "Epoch 72/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0157 - acc: 0.9953 - val_loss: 1.8158 - val_acc: 0.8667\n",
      "Epoch 73/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0285 - acc: 0.9938 - val_loss: 2.0265 - val_acc: 0.8667\n",
      "Epoch 74/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0190 - acc: 0.9951 - val_loss: 3.9821 - val_acc: 0.7333\n",
      "Epoch 75/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0133 - acc: 0.9962 - val_loss: 4.1400 - val_acc: 0.7333\n",
      "Epoch 76/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0262 - acc: 0.9944 - val_loss: 2.8930 - val_acc: 0.8000\n",
      "Epoch 77/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0136 - acc: 0.9964 - val_loss: 3.2517 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0063 - acc: 0.9982 - val_loss: 3.2263 - val_acc: 0.8000\n",
      "Epoch 79/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0169 - acc: 0.9953 - val_loss: 4.9610 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0190 - acc: 0.9962 - val_loss: 0.7371 - val_acc: 0.8667\n",
      "Epoch 81/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0266 - acc: 0.9936 - val_loss: 2.4513 - val_acc: 0.7333\n",
      "Epoch 82/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0258 - acc: 0.9940 - val_loss: 2.3398 - val_acc: 0.7333\n",
      "Epoch 83/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0094 - acc: 0.9962 - val_loss: 2.4129 - val_acc: 0.8000\n",
      "Epoch 84/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0201 - acc: 0.9951 - val_loss: 1.9667 - val_acc: 0.8000\n",
      "Epoch 85/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0240 - acc: 0.9960 - val_loss: 4.0852 - val_acc: 0.7333\n",
      "Epoch 86/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0097 - acc: 0.9973 - val_loss: 2.2178 - val_acc: 0.8000\n",
      "Epoch 87/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0301 - acc: 0.9938 - val_loss: 3.5490 - val_acc: 0.6667\n",
      "Epoch 88/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0199 - acc: 0.9960 - val_loss: 4.2982 - val_acc: 0.7333\n",
      "Epoch 89/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0159 - acc: 0.9967 - val_loss: 5.2406 - val_acc: 0.6667\n",
      "Epoch 90/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0225 - acc: 0.9956 - val_loss: 4.1988 - val_acc: 0.6667\n",
      "Epoch 91/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0225 - acc: 0.9951 - val_loss: 2.2418 - val_acc: 0.8000\n",
      "Epoch 92/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0176 - acc: 0.9958 - val_loss: 0.2707 - val_acc: 0.8000\n",
      "Epoch 93/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0310 - acc: 0.9936 - val_loss: 2.9949 - val_acc: 0.7333\n",
      "Epoch 94/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0199 - acc: 0.9967 - val_loss: 2.9995 - val_acc: 0.7333\n",
      "Epoch 95/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0156 - acc: 0.9964 - val_loss: 2.8071 - val_acc: 0.8000\n",
      "Epoch 96/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0156 - acc: 0.9964 - val_loss: 2.1523 - val_acc: 0.8667\n",
      "Epoch 97/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0224 - acc: 0.9953 - val_loss: 2.6544 - val_acc: 0.8000\n",
      "Epoch 98/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0192 - acc: 0.9958 - val_loss: 3.0694 - val_acc: 0.8000\n",
      "Epoch 99/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0313 - acc: 0.9927 - val_loss: 2.5814 - val_acc: 0.8000\n",
      "Epoch 100/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0125 - acc: 0.9973 - val_loss: 2.1546 - val_acc: 0.8667\n",
      "Epoch 101/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0189 - acc: 0.9962 - val_loss: 2.4483 - val_acc: 0.8000\n",
      "Epoch 102/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0104 - acc: 0.9958 - val_loss: 2.5535 - val_acc: 0.8000\n",
      "Epoch 103/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0330 - acc: 0.9929 - val_loss: 2.5424 - val_acc: 0.8000\n",
      "Epoch 104/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0163 - acc: 0.9960 - val_loss: 2.5093 - val_acc: 0.8000\n",
      "Epoch 105/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0159 - acc: 0.9956 - val_loss: 2.1236 - val_acc: 0.8667\n",
      "Epoch 106/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0212 - acc: 0.9951 - val_loss: 2.5080 - val_acc: 0.8000\n",
      "Epoch 107/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0105 - acc: 0.9960 - val_loss: 3.2473 - val_acc: 0.8000\n",
      "Epoch 108/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0150 - acc: 0.9960 - val_loss: 1.8176 - val_acc: 0.8667\n",
      "Epoch 109/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0134 - acc: 0.9978 - val_loss: 1.7268 - val_acc: 0.8667\n",
      "Epoch 110/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0176 - acc: 0.9942 - val_loss: 1.0805 - val_acc: 0.9333\n",
      "Epoch 111/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0116 - acc: 0.9978 - val_loss: 1.8451 - val_acc: 0.8667\n",
      "Epoch 112/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0155 - acc: 0.9960 - val_loss: 3.1680 - val_acc: 0.7333\n",
      "Epoch 113/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0110 - acc: 0.9971 - val_loss: 2.1504 - val_acc: 0.8000\n",
      "Epoch 114/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0130 - acc: 0.9984 - val_loss: 2.3898 - val_acc: 0.8000\n",
      "Epoch 115/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0310 - acc: 0.9953 - val_loss: 2.2475e-04 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0137 - acc: 0.9969 - val_loss: 2.6463 - val_acc: 0.8000\n",
      "Epoch 117/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0237 - acc: 0.9964 - val_loss: 2.5407 - val_acc: 0.8000\n",
      "Epoch 118/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0326 - acc: 0.9951 - val_loss: 3.2911 - val_acc: 0.7333\n",
      "Epoch 119/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0247 - acc: 0.9947 - val_loss: 2.5825 - val_acc: 0.8000\n",
      "Epoch 120/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0098 - acc: 0.9984 - val_loss: 1.7466 - val_acc: 0.8000\n",
      "Epoch 121/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0226 - acc: 0.9958 - val_loss: 3.4307 - val_acc: 0.7333\n",
      "Epoch 122/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0197 - acc: 0.9951 - val_loss: 2.2570 - val_acc: 0.8000\n",
      "Epoch 123/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0086 - acc: 0.9987 - val_loss: 3.2245 - val_acc: 0.8000\n",
      "Epoch 124/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0232 - acc: 0.9964 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0222 - acc: 0.9973 - val_loss: 2.8362 - val_acc: 0.7333\n",
      "Epoch 126/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0180 - acc: 0.9973 - val_loss: 2.1916 - val_acc: 0.8667\n",
      "Epoch 127/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0162 - acc: 0.9951 - val_loss: 1.0746 - val_acc: 0.9333\n",
      "Epoch 128/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0175 - acc: 0.9958 - val_loss: 3.3845 - val_acc: 0.7333\n",
      "Epoch 129/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0142 - acc: 0.9967 - val_loss: 3.2246 - val_acc: 0.8000\n",
      "Epoch 130/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0212 - acc: 0.9960 - val_loss: 3.2267 - val_acc: 0.8000\n",
      "Epoch 131/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0161 - acc: 0.9964 - val_loss: 3.6509 - val_acc: 0.7333\n",
      "Epoch 132/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0335 - acc: 0.9936 - val_loss: 3.1347 - val_acc: 0.7333\n",
      "Epoch 133/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0244 - acc: 0.9956 - val_loss: 2.8380 - val_acc: 0.7333\n",
      "Epoch 134/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0102 - acc: 0.9980 - val_loss: 3.4367 - val_acc: 0.7333\n",
      "Epoch 135/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0299 - acc: 0.9953 - val_loss: 1.4498 - val_acc: 0.8667\n",
      "Epoch 136/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0169 - acc: 0.9960 - val_loss: 2.0143 - val_acc: 0.8000\n",
      "Epoch 137/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0138 - acc: 0.9956 - val_loss: 4.6493 - val_acc: 0.6667\n",
      "Epoch 138/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0208 - acc: 0.9969 - val_loss: 2.6068 - val_acc: 0.8000\n",
      "Epoch 139/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0195 - acc: 0.9953 - val_loss: 3.8021 - val_acc: 0.7333\n",
      "Epoch 140/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0176 - acc: 0.9960 - val_loss: 1.0995 - val_acc: 0.9333\n",
      "Epoch 141/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0119 - acc: 0.9973 - val_loss: 2.3988 - val_acc: 0.8000\n",
      "Epoch 142/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0103 - acc: 0.9976 - val_loss: 3.4659 - val_acc: 0.7333\n",
      "Epoch 143/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0161 - acc: 0.9964 - val_loss: 3.3639 - val_acc: 0.7333\n",
      "Epoch 144/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0234 - acc: 0.9958 - val_loss: 3.4383 - val_acc: 0.7333\n",
      "Epoch 145/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0233 - acc: 0.9944 - val_loss: 2.3821 - val_acc: 0.8000\n",
      "Epoch 146/200\n",
      "1500/1500 [==============================] - 12s - loss: 0.0106 - acc: 0.9964 - val_loss: 2.1959 - val_acc: 0.8000\n",
      "Epoch 147/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0225 - acc: 0.9958 - val_loss: 2.9133 - val_acc: 0.7333\n",
      "Epoch 148/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0091 - acc: 0.9976 - val_loss: 2.7669 - val_acc: 0.7333\n",
      "Epoch 149/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0197 - acc: 0.9969 - val_loss: 2.2369 - val_acc: 0.8000\n",
      "Epoch 150/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0205 - acc: 0.9958 - val_loss: 2.8869 - val_acc: 0.7333\n",
      "Epoch 151/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0259 - acc: 0.9960 - val_loss: 1.1364 - val_acc: 0.8667\n",
      "Epoch 152/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0093 - acc: 0.9971 - val_loss: 2.9186 - val_acc: 0.7333\n",
      "Epoch 153/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0268 - acc: 0.9956 - val_loss: 3.8377 - val_acc: 0.7333\n",
      "Epoch 154/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0176 - acc: 0.9967 - val_loss: 3.2665 - val_acc: 0.8000\n",
      "Epoch 155/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0262 - acc: 0.9956 - val_loss: 3.2237 - val_acc: 0.8000\n",
      "Epoch 156/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0156 - acc: 0.9973 - val_loss: 2.8077 - val_acc: 0.8000\n",
      "Epoch 157/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0071 - acc: 0.9980 - val_loss: 4.1667 - val_acc: 0.7333\n",
      "Epoch 158/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0208 - acc: 0.9964 - val_loss: 2.1499 - val_acc: 0.8667\n",
      "Epoch 159/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0123 - acc: 0.9969 - val_loss: 3.4025 - val_acc: 0.7333\n",
      "Epoch 160/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0176 - acc: 0.9971 - val_loss: 3.4498 - val_acc: 0.7333\n",
      "Epoch 161/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0266 - acc: 0.9962 - val_loss: 3.5413 - val_acc: 0.7333\n",
      "Epoch 162/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0413 - acc: 0.9951 - val_loss: 3.0390 - val_acc: 0.6667\n",
      "Epoch 163/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0256 - acc: 0.9956 - val_loss: 2.7056 - val_acc: 0.8000\n",
      "Epoch 164/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0192 - acc: 0.9969 - val_loss: 1.6593 - val_acc: 0.8667\n",
      "Epoch 165/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0375 - acc: 0.9951 - val_loss: 5.6663 - val_acc: 0.6000\n",
      "Epoch 166/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0220 - acc: 0.9958 - val_loss: 2.0501 - val_acc: 0.7333\n",
      "Epoch 167/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0328 - acc: 0.9956 - val_loss: 2.4574 - val_acc: 0.8000\n",
      "Epoch 168/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0141 - acc: 0.9982 - val_loss: 3.2355 - val_acc: 0.8000\n",
      "Epoch 169/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0134 - acc: 0.9971 - val_loss: 2.6877 - val_acc: 0.8000\n",
      "Epoch 170/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0197 - acc: 0.9969 - val_loss: 4.8125 - val_acc: 0.6000\n",
      "Epoch 171/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0268 - acc: 0.9953 - val_loss: 2.9920 - val_acc: 0.7333\n",
      "Epoch 172/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0030 - acc: 0.9987 - val_loss: 2.6713 - val_acc: 0.8000\n",
      "Epoch 173/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0365 - acc: 0.9940 - val_loss: 2.1491 - val_acc: 0.8667\n",
      "Epoch 174/200\n",
      "1500/1500 [==============================] - 13s - loss: 0.0239 - acc: 0.9949 - val_loss: 3.3814 - val_acc: 0.6667\n",
      "Epoch 175/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0231 - acc: 0.9958 - val_loss: 3.2238 - val_acc: 0.8000\n",
      "Epoch 176/200\n",
      "1500/1500 [==============================] - 14s - loss: 0.0154 - acc: 0.9960 - val_loss: 5.4263 - val_acc: 0.6000\n",
      "Epoch 177/200\n",
      "1500/1500 [==============================] - 15s - loss: 0.0149 - acc: 0.9960 - val_loss: 2.1495 - val_acc: 0.8667\n",
      "Epoch 178/200\n",
      "1500/1500 [==============================] - 16s - loss: 0.0074 - acc: 0.9982 - val_loss: 1.3426 - val_acc: 0.8667\n",
      "Epoch 179/200\n",
      "1500/1500 [==============================] - 17s - loss: 0.0366 - acc: 0.9942 - val_loss: 3.2535 - val_acc: 0.8000\n",
      "Epoch 180/200\n",
      "1500/1500 [==============================] - 18s - loss: 0.0227 - acc: 0.9958 - val_loss: 3.1861 - val_acc: 0.8000\n",
      "Epoch 181/200\n",
      "1500/1500 [==============================] - 20s - loss: 0.0234 - acc: 0.9951 - val_loss: 2.9251 - val_acc: 0.8000\n",
      "Epoch 182/200\n",
      "1500/1500 [==============================] - 23s - loss: 0.0285 - acc: 0.9960 - val_loss: 1.0747 - val_acc: 0.9333\n",
      "Epoch 183/200\n",
      "1500/1500 [==============================] - 25s - loss: 0.0108 - acc: 0.9969 - val_loss: 3.2329 - val_acc: 0.8000\n",
      "Epoch 184/200\n",
      "1500/1500 [==============================] - 21s - loss: 0.0327 - acc: 0.9953 - val_loss: 2.8161 - val_acc: 0.8000\n",
      "Epoch 185/200\n",
      "1500/1500 [==============================] - 25s - loss: 0.0317 - acc: 0.9960 - val_loss: 2.6764 - val_acc: 0.8000\n",
      "Epoch 186/200\n",
      "1500/1500 [==============================] - 25s - loss: 0.0254 - acc: 0.9956 - val_loss: 3.2259 - val_acc: 0.8000\n",
      "Epoch 187/200\n",
      "1500/1500 [==============================] - 28s - loss: 0.0220 - acc: 0.9960 - val_loss: 4.0109 - val_acc: 0.6667\n",
      "Epoch 188/200\n",
      "1500/1500 [==============================] - 28s - loss: 0.0169 - acc: 0.9967 - val_loss: 3.8171 - val_acc: 0.7333\n",
      "Epoch 189/200\n",
      "1500/1500 [==============================] - 30s - loss: 0.0154 - acc: 0.9976 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 190/200\n",
      "1500/1500 [==============================] - 26s - loss: 0.0241 - acc: 0.9953 - val_loss: 3.4476 - val_acc: 0.7333\n",
      "Epoch 191/200\n",
      "1500/1500 [==============================] - 33s - loss: 0.0106 - acc: 0.9967 - val_loss: 2.7696 - val_acc: 0.8000\n",
      "Epoch 192/200\n",
      "1500/1500 [==============================] - 32s - loss: 0.0253 - acc: 0.9953 - val_loss: 3.6503 - val_acc: 0.6667\n",
      "Epoch 193/200\n",
      "1500/1500 [==============================] - 41s - loss: 0.0133 - acc: 0.9976 - val_loss: 2.8289 - val_acc: 0.7333\n",
      "Epoch 194/200\n",
      "1500/1500 [==============================] - 47s - loss: 0.0451 - acc: 0.9920 - val_loss: 3.2236 - val_acc: 0.8000\n",
      "Epoch 195/200\n",
      "1500/1500 [==============================] - 54s - loss: 0.0296 - acc: 0.9953 - val_loss: 2.7113 - val_acc: 0.8000\n",
      "Epoch 196/200\n",
      "1500/1500 [==============================] - 58s - loss: 0.0349 - acc: 0.9944 - val_loss: 1.2201 - val_acc: 0.8667\n",
      "Epoch 197/200\n",
      "1500/1500 [==============================] - 59s - loss: 0.0145 - acc: 0.9973 - val_loss: 3.2887 - val_acc: 0.7333\n",
      "Epoch 198/200\n",
      "1500/1500 [==============================] - 58s - loss: 0.0187 - acc: 0.9967 - val_loss: 3.2297 - val_acc: 0.8000\n",
      "Epoch 199/200\n",
      "1500/1500 [==============================] - 59s - loss: 0.0193 - acc: 0.9964 - val_loss: 2.8833 - val_acc: 0.8000\n",
      "Epoch 200/200\n",
      "1500/1500 [==============================] - 59s - loss: 0.0231 - acc: 0.9964 - val_loss: 1.4149 - val_acc: 0.8667\n",
      "-- Evaluate --\n",
      "acc: 86.67%\n",
      "-- Predict --\n",
      "{'circle': 0, 'triangle': 2, 'rectangle': 1}\n",
      "[[0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.999 0.001 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.993 0.007 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.068 0.932 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000]]\n"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.7,\n",
    "                                   zoom_range=[0.9, 2.2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/test',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15 * 100,\n",
    "        epochs=200,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.67%의 정확도를 얻었습니다. 만족할만한 수준은 아니지만, 도전 시험셋으로 기존 모델을 시험했을 때의 결과가 50%를 못 미치는 수준에 비하면 비약적인 개선이 일어났습니다. 이는 동일한 모델을 사용하면서 훈련 데이터만 부풀려서 학습을 시켰을 뿐인데 성능 향상이 일어났습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 요약\n",
    "\n",
    "원, 삼각형, 사각형을 분류하는 간단한 문제에서도 개발 모델이 현실에 적용하기 위해서는 어떠한 어려움이 있는 지 알게되었습니다. 그리고 이를 극복하는 방안으로 데이터 부풀리기 방법에 대해서 알아보고, 각 파라미터 별로 어떻게 데이터를 부풀리는 지 생성된 이미지를 통해 살펴보왔습니다. 훈련셋이 충분하지 않거나 시험셋의 다양한 특성을 반영되어 있지 않다면 데이터 부풀리기 방법은 성능 개선에 큰 도움을 줄 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/lecture/)\n",
    "* 이전 : [컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/2017/03/08/CNN_Getting_Started/)\n",
    "* 다음 : [순환 신경망 레이어 이야기](https://tykimos.github.io/2017/04/09/RNN_Getting_Started/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
