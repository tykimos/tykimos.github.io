{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named object_detector.file_io",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97197e4d289e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named object_detector.file_io"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import object_detector.file_io as file_io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import object_detector.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "import pandas as pd\n",
    "\n",
    "class Evaluator(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._recall_precision = None\n",
    "        self._dataset = None\n",
    "    \n",
    "    def eval_average_precision(self, test_image_files, \n",
    "                               annotation_path, \n",
    "                               detector, \n",
    "                               window_dim, window_step, pyramid_scale):\n",
    "        \n",
    "        \"\"\"Public function to calculate average precision of the detector.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_image_files : list of str\n",
    "            list of test image filenames to evaluate detector's performance\n",
    "    \n",
    "        annotation_path : str\n",
    "            annotation directory path for test_image_files\n",
    "        \n",
    "        detector : Detector\n",
    "            instance of Detector class\n",
    "        \n",
    "        window_dim : list\n",
    "            (height, width) order of sliding window size\n",
    "            \n",
    "        window_step : list\n",
    "            (height_step, width_step) order of sliding window step\n",
    "            \n",
    "        pyramid_scale : float\n",
    "            scaling ratio of building image pyramid\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        average_precision : float\n",
    "            evaluated score for the detector and test images on average precision. \n",
    "    \n",
    "        Examples\n",
    "        --------\n",
    "        \"\"\"\n",
    "        \n",
    "        patches = []\n",
    "        probs = []\n",
    "        gts = []\n",
    "        \n",
    "        # setup the progress bar\n",
    "        widgets = [\"Running for each Test image as gathering patches and its probabilities: \", \n",
    "                   progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "        pbar = progressbar.ProgressBar(maxval=len(test_image_files), widgets=widgets).start()\n",
    "        \n",
    "        for i, image_file in enumerate(test_image_files):\n",
    "            test_image = cv2.imread(image_file)\n",
    "            test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            boxes, probs_ = detector.run(test_image, \n",
    "                                         window_dim, window_step, pyramid_scale, \n",
    "                                         threshold_prob=0.0,\n",
    "                                         show_result=False, \n",
    "                                         show_operation=False)\n",
    "              \n",
    "            truth_bb = self._get_truth_bb(image_file, annotation_path)\n",
    "            ious = self._calc_iou(boxes, truth_bb)\n",
    "            is_positive = ious > 0.5\n",
    "             \n",
    "            patches += boxes.tolist()\n",
    "            probs += probs_.tolist()\n",
    "            gts += is_positive.tolist()\n",
    "            \n",
    "            pbar.update(i)\n",
    "        pbar.finish()\n",
    "    \n",
    "        probs = np.array(probs)\n",
    "        gts = np.array(gts)\n",
    "\n",
    "        self._calc_precision_recall(probs, gts)\n",
    "        average_precision = self._calc_average_precision()\n",
    "        \n",
    "        return average_precision\n",
    "    \n",
    "    def plot_recall_precision(self):\n",
    "        \"\"\"Function to plot recall-precision graph.\n",
    "        \n",
    "        It should be performed eval_average_precision() before this function is called.\n",
    "        \"\"\"\n",
    "        range_offset = 0.1\n",
    "        \n",
    "        if self._recall_precision is None:\n",
    "            raise ValueError('Property _recall_precision is not calculated. To calculate this, run eval_average_precision() first.')\n",
    "        \n",
    "        recall_precision = self._recall_precision\n",
    "        \n",
    "        plt.plot(recall_precision[:, 0], recall_precision[:, 1], \"r-\")\n",
    "        plt.plot(recall_precision[:, 0], recall_precision[:, 1], \"ro\")\n",
    "        plt.axis([0 - range_offset, 1 + range_offset, 0 - range_offset, 1 + range_offset])\n",
    "        plt.xlabel(\"recall\")\n",
    "        plt.ylabel(\"precision\")\n",
    "        plt.show()\n",
    "    \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        if self._dataset is None:\n",
    "            raise ValueError('Property _dataset is not calculated. To calculate this, run eval_average_precision() first.')\n",
    "    \n",
    "        d = {\"probability\": self._dataset[:,0], 'ground truth': self._dataset[:,1].astype(np.bool_)}\n",
    "        df = pd.DataFrame(data=d, columns = [\"probability\", 'ground truth'])\n",
    "        return df\n",
    "    \n",
    "    def _calc_average_precision(self):\n",
    "        \n",
    "        inter_precisions = []\n",
    "        for i in range(11):\n",
    "            recall = float(i) / 10\n",
    "            inter_precisions.append(self._calc_interpolated_precision(recall))\n",
    "            \n",
    "        return np.array(inter_precisions).mean()\n",
    "\n",
    "    \n",
    "    def _calc_precision_recall(self, probs, ground_truths):\n",
    "        probs = np.array(probs)\n",
    "        ground_truths = np.array(ground_truths)\n",
    "        \n",
    "        dataset = np.concatenate([probs.reshape(-1,1), ground_truths.reshape(-1,1)], axis=1)\n",
    "        dataset = dataset[dataset[:, 0].argsort()[::-1]]\n",
    "        \n",
    "        n_gts = len(dataset[dataset[:, 1] == 1])\n",
    "        n_relevant = 0.0\n",
    "        n_searched = 0.0\n",
    "        \n",
    "        recall_precision = []\n",
    "        \n",
    "        for data in dataset:\n",
    "            n_searched += 1\n",
    "            if data[1] == 1:\n",
    "                n_relevant += 1\n",
    "            recall = n_relevant / n_gts\n",
    "            precision = n_relevant / n_searched\n",
    "            recall_precision.append((recall, precision))\n",
    "            \n",
    "            if recall == 1.0:\n",
    "                break\n",
    "        \n",
    "        self._dataset = dataset\n",
    "        self._recall_precision = np.array(recall_precision)\n",
    "    \n",
    "    def _calc_interpolated_precision(self, desired_recall):\n",
    "        recall_precision = self._recall_precision\n",
    "        \n",
    "        inter_precision = recall_precision[recall_precision[:,0] >= desired_recall]\n",
    "        inter_precision = inter_precision[:, 1]\n",
    "        inter_precision = max(inter_precision)\n",
    "        return inter_precision\n",
    "    \n",
    "    def _calc_iou(self, boxes, truth_box):\n",
    "        y1 = boxes[:, 0]\n",
    "        y2 = boxes[:, 1]\n",
    "        x1 = boxes[:, 2]\n",
    "        x2 = boxes[:, 3]\n",
    "        \n",
    "        y1_gt = truth_box[0]\n",
    "        y2_gt = truth_box[1]\n",
    "        x1_gt = truth_box[2]\n",
    "        x2_gt = truth_box[3]\n",
    "        \n",
    "        xx1 = np.maximum(x1, x1_gt)\n",
    "        yy1 = np.maximum(y1, y1_gt)\n",
    "        xx2 = np.minimum(x2, x2_gt)\n",
    "        yy2 = np.minimum(y2, y2_gt)\n",
    "    \n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        \n",
    "        intersections = w*h\n",
    "        As = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        B = (x2_gt - x1_gt + 1) * (y2_gt - y1_gt + 1)\n",
    "        \n",
    "        ious = intersections.astype(float) / (As + B -intersections)\n",
    "        return ious\n",
    "\n",
    "\n",
    "    # Todo : extractor module과 중복되는 내용 제거\n",
    "    def _get_truth_bb(self, image_file, annotation_path):\n",
    "        image_id = utils.get_file_id(image_file)\n",
    "        annotation_file = \"{}/annotation_{}.mat\".format(annotation_path, image_id)\n",
    "        bb = file_io.FileMat().read(annotation_file)[\"box_coord\"][0]\n",
    "        return bb\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
