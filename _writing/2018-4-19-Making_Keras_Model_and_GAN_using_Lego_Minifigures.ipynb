{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"레고사람으로 만들어보는 케라스 모델과 GAN(약혐주의)\"\n",
    "author: 김태영\n",
    "date:   2017-01-27 04:00:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_10.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델을 레고사람으로 비유해보고 어떻게 모델이 학습되는 지 살펴본 뒤 기본적인 모델부터 GAN 모델까지 만들어보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고 사람과 모델의 구성요소\n",
    "\n",
    "레고 사람은 크게 머리, 상반신, 하반신 이렇게 3가지로 나눌 수 있습니다. 각각 특징을 살펴보겠습니다. \n",
    "* 머리 : 눈과 입이 있고, 보이지는 않지만 생각할 수 있는 뇌가 있습니다.\n",
    "* 상반신 : 몸통과 두 팔이 달려있고, 두 손은 무언가를 잡을 수가 있습니다.\n",
    "* 하반신 : 두 다리가 있으며 걸을 수 있습니다.\n",
    "\n",
    "    레고 사람은 머리, 상반신, 하반신으로 구성되어 있다.\n",
    "    \n",
    "![img](http://tykimos.github.io/warehouse/2018-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_1.png)\n",
    "\n",
    "이번에는 딥러닝 모델을 살펴보겠습니다. 딥러닝 모델은 크게 네트워크, 목표함수, 최적화기로 구성되어 있습니다.\n",
    "* 네트워크 : 여러층의 다양한 레이어로 구성되어 있습니다. 이렇게 쌓은 레이어에 데이터를 입력하면, 레이어들의 내부 연산을 통해 결과값이 출력됩니다.\n",
    "* 목표함수 : 딥러닝 모델의 학습 목표를 설정하는 것이며, 학습 목표 기준으로 네트워크의 출력과 실제 정답이 얼마나 차이나는 지를 계산합니다.\n",
    "* 최적화기 : 목표함수로부터 계산된 차이에 따라 네트워크를 갱신합니다.\n",
    "\n",
    "    딥러닝 모델은 네트워크, 목표함수, 최적화기로 구성되어 있다.\n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_2.png)\n",
    "\n",
    "레고 사람과 딥러닝 모델을 매칭하면 다음과 같습니다.\n",
    "* 머리 = 네트워크\n",
    "* 상반신 = 목표함수\n",
    "* 하반신 = 최적화기\n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고 사람 머리 이용하기\n",
    "\n",
    "레고 사람의 머리를 좀 더 살펴보겠습니다. 머리를 보면, 눈, 입이 있고, 보이지 않지만 뇌가 있다고 가정을 해보겠습니다. 이 뇌가 딥러닝 모델에서의 네트워크를 말하며, 네트워크는 다시 아키텍처와 가중치로 구성됩니다. 아키텍처는 구성된 레이어들의 내부 및 연결 구조를 말하며, 각 레이어들 속에 입력 뉴런과 출력 뉴런과의 연결강도를 의미하는 가중치 정보가 포함되어 있습니다. 레이어를 레고 블록으로 표시할 수 있으며, 몇 개의 블록을 조립하여 아키텍처를 구성할 수 있습니다. 즉 머리 안에는 조립된 레고 블록이 들어가 있다고 생각하시면 됩니다. 레고 블록에 대해서 더 궁금하시면 '블록과 함께하는 파이썬 딥러닝 케라스' 책을 참고하세요. \n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_4.png)\n",
    "\n",
    "정보가 눈으로 들어가면 이 정보가 네트워크에 입력입니다. 입력된 정보는 네트워크의 아키텍처와 가중치에 의해 결과값이 계산되고 이 값이 입으로 출력됩니다. 이 과정을 다음 그림처럼 나타낼 수 있습니다. \n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_5.png)\n",
    "\n",
    "우리가 딥러닝 모델에 원하는 작동은 입력이 주어졌을 때, 출력이 나오는 것입니다. 이를 위해서는 레고 사람 머리 즉 네트워크만 있어도 딥러닝 모델을 사용할 수 있습니다. 대신 네트워크가 학습이 되지 않은 상태이기 때문에 랜덤한 출력이 나오겠죠? 정말 네트워크만으로 작동이 가능한 지 케라스 코드로 확인해보겠습니다. 1에서 10까지 숫자를 입력하면 홀수와 짝수를 알려주는 모델을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 필요한 패키지를 불러옵니다.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 시퀀스 모델을 생성합니다.\n",
    "model = Sequential()\n",
    "\n",
    "# 생성한 시퀀스 모델에 3개 레이어를 쌓습니다. \n",
    "model.add(Dense(6, input_dim=1, activation='relu')) # 입력이 숫자 하나이고 출력이 6개인 레이어입니다.\n",
    "model.add(Dense(8, activation='relu')) # 입력이 6개이고 출력이 8개인 레이어입니다.\n",
    "model.add(Dense(1, activation='sigmoid')) # 입력이 8개이고 출력이 1개인 레이어입니다.\n",
    "\n",
    "X_hat = np.array([[3]]) # numpy 패키지를 이용해서 숫자 '3'인 입력을 하나 만듭니다.\n",
    "Y_hat = model.predict(X_hat) # 앞서 만든 숫자 '3'을 모델의 네트워크에 입력한 뒤 계산된 출력값을 y_hat에 저장합니다.\n",
    "\n",
    "print(Y_hat) # y_hat을 화면에 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크의 마지막 출력층의 활성화(activation)함수를 시그모이드(sigmoid)로 사용하였기 때문에 0.0과 1.0 사이의 실수값이 출력됩니다. 시그모이드를 사용하는 이유는 0.5를 기준으로 0.5보다 작은 값이 나오면 홀수, 0.5보다 큰 값이 나오면 짝수라고 가정하기 쉽기 때문이죠. 물론 그 반대로 지정해도 되고, 0.5가 아니라 다른 값을 기준값으로 지정해야 됩니다. 우리는 이것을 임계값이라고 부릅니다. 예제에서 숫자 '3'을 입력했기 때문에 0.5보다 적으면서 0.0에 가까운 결과가 나오길 기도해봅시다.\n",
    "    \n",
    "위 예제를 실행해보면 0.5보다 적은 값이 나올 수도 있겠지만 여러번 해보면 결과가 그때 그때 다릅니다. 네트워크는 현재 아무런 데이터도 학습을 하지 않은 상태이기 때문에 네트워크의 가중치도 랜덤값이 저장되어 있으며 따라서 출력값도 0.0과 1.0사이의 랜덤값이 나오기 때문이죠. 이제 우리가 원하는 값을 얻으려면 네트워크를 학습시켜야 되겠죠? 네트워크를 학습시키기 위해서는 목표함수와 최적화기가 필요하며, 레고 사람에서는 상반신과 하반신이 필요합니다. 딥러닝 모델이 학습된 후 사용할 때는 역시 네트워크만 있으면 됩니다. \n",
    "\n",
    "    학습하지 않은 네트워크는 아무말 대잔치이다. 마치 갓 태어난 아기가 옹알이하는 것과 같다.\n",
    "    \n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고 사람 조립하기\n",
    "\n",
    "자 이제 머리, 상반신, 하반신을 꽂아서 하나의 레고 사람으로 만들어보겠습니다. 이 과정은 네트워크, 목표함수, 최적화기를 하나로 묶어 딥러닝 모델을 만드는 것과 같습니다. 케라스에서는 이 과정을 '컴파일'이라고 부릅니다.\n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_7.png)\n",
    "\n",
    "머리, 상반신, 하반신이 하나씩만 있으면 쉽게 조립할 수 있겠지만, 여러개의 레고 사람들이 분리되어 있다면 조립하기가 쉽지가 않습니다. 모두 제 짝이 있기 때문에 잘 맞추어야 제대로된 레고 사람이 나오겠죠? 아래 그림을 오려서 직접 조립해보세요. (책이 아니라면 출력해서...) 즉 우리는 어떤 문제를 풀기 위해 적절한 네트워크, 목표함수, 최적화기를 골라 컴파일하여 모델을 구성해야 합니다. \n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_8.png)\n",
    "\n",
    "홀수와 짝수를 구분하는 문제에서는 두가지를 분류하는 이진분류이므로 목표함수는 'binary_crossentropy'으로 설정하고, 최적화기는 일반적으로 사용되는 'adam'으로 설정해보겠습니다. 이를 레고 사람으로 표시하면 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 레고 사람을 케라스 코드로 표현하면 다음과 같습니다. complie 함수에 loss 인자에는 목표함수를 설정하고, optimizer 인자에는 최적화기를 설정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일까지 하였다면 모델이 학습할 준비를 마치게 된 것입니다. 그럼 학습을 시켜볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고 사람 학습시키기\n",
    "\n",
    "학습 과정 이해하기 위해 먼저 아래 간단한 수식을 살펴보겠습니다. 앞에서 네트워크의 출력은 아키텍처와 가중치에 의해 계산된다고 설명드렸는데, 바로 이 간단한 수식으로 계산이 되는 것입니다.\n",
    "\n",
    "    Y' = w * X + b\n",
    "    \n",
    "각 변수의 의미는 다음과 같습니다.\n",
    "    \n",
    "    Y' : 네트워크에 의해 계산된 결과값 (푼답)\n",
    "    w, b : 네트워크의 가중치\n",
    "    X : 네트워크의 입력값 (문제)\n",
    "    \n",
    "이것은 마치 학생이 문제를 푸는 것과 동일합니다. 하지만 학생이 제대로 풀었는 지 확인하기 위해서는 정답도 있어야 겠죠? 이 정답을 Y이라고 하죠. 정답을 학생한테 알려주면 푼답(Y')과 정답(Y)을 비교한 후 '아하'라고 하면서 학습을 하게 됩니다. 즉 머리 속의 가중치(w, b)가 갱신되는 것입니다. 그래서 학습을 위해 우리가 준비해야할 것은 바로 문제(X)와 정답(Y)입니다.\n",
    "\n",
    "    우리가 준비해야 할 것은 문제(X)와 정답(Y)이다.\n",
    "    \n",
    "그럼 본격적으로 레고 사람을 학습시켜보겠습니다. 아래 그림처럼 앞서 조립한 레고 사람과 우리가 준비한 X, Y가 있다고 가정해봅니다.\n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_9.png)\n",
    "\n",
    "우리가 준비한 X(문제)를 레고 사람의 네트워크에 입력하면, 네트워크는 현재 가지고 있는 가중치(w, b)를 이용하여 Y' = w * X + b 식에 의해 Y'(푼답)을 출력합니다. \n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_10.png)\n",
    "\n",
    "그 다음 상반신(목표 함수)의 한 손에는 네트워크가 푼 답인 Y'을 주고, 또 다른 한 손에는 우리가 준비한 정답 Y를 줍니다. 그럼 목표함수는 양 손에 쥔 두 답 Y와 Y'을 비교하여 손실값을 계산합니다. 차이값이 아니라 손실값이라고 말하는 이유는 Y와 Y'이 수치적으로 차이가 많이 나더라도 목표에 따라 손실이 적을 수도 있고 반대로 수치적으로는 차이가 적더라도 손실값이 클 수가 있습니다. 목표함수에서 중요한 것은 푼 답과 정답 사이의 수치적인 차이가 아니라 목표를 달성하기 위해서 얼마나 손실이 일어났는 지를 아는 것입니다.\n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_11.png)\n",
    "\n",
    "목표함수로부터 계산한 손실값은 최적화기에 전달됩니다. 최적화기는 정해진 알고리즘에 의해 손실값에 따라 네트워크를 갱신합니다. 엄밀히 얘기하면 네트워크의 가중치가 갱신됩니다. Y' = w * X + b 식에서 보면 w와 b가 바뀌게 됩니다. 이 과정이 반복되면서 손실값이 작은 방향으로 다시말해 네트워크가 푼 답과 정답과의 차이가 적어지도록 학습됩니다. \n",
    "\n",
    "![img](http://tykimos.github.io/warehouse/2017-4-19-Making_Keras_Model_and_GAN_using_Lego_Minifigures_12.png)\n",
    "\n",
    "학습과정에 대해서 알아봤으니 케라스로 홀짝을 구분하는 모델을 학습시켜보겠습니다. 먼저 학습시켜야 할 문제와 정답을 준비해야겠죠? 아래 코드는 1에서 10까지 숫자들을 X 변수에 넣고, 각 숫자에 해당하는 정답을 Y 변수에 넣습니다. 이 때 홀수는 0, 짝수는 1로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]) # 숫자 1에서 10까지의 문제 준비\n",
    "Y = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1]]) # 숫자 1에서 10까지의 정답 준비, 홀수는 0, 짝수는 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X, Y를 준비했으니 모델에 학습을 시켜봅니다. 케라스에서는 우리가 준비한 X, Y을 fit 함수에 입력하여 모델을 학습시킵니다. fit 함수의 주요인자로는 에포크와 배치사이즈가 있습니다. 에포크는 우리가 준비한 문제와 정답을 몇 번 반복해서 학습하느냐를 나타내고, 배치사이즈는 몇 문항을 풀고 푼 답과 정답을 맞춰볼까를 지정하는 옵션입니다. 에포크가 100이고, 배치사이즈가 5이라면 우리가 준비한 10문항을 100번 반복해서 풀며, 5문항 푼 뒤 푼 답과 정답을 맞추게 됩니다. 결론적으론 총 1000 문항(10문항 x 100 에포크)을 풀게되며, 200번(1000문항 / 5 배치사이즈)의 네트워크 갱신이 일어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, Y, epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s - loss: 1.1770 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s - loss: 1.1492 - acc: 0.4000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s - loss: 1.1233 - acc: 0.4000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s - loss: 1.0980 - acc: 0.4000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s - loss: 1.0732 - acc: 0.4000\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s - loss: 1.0490 - acc: 0.4000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s - loss: 1.0255 - acc: 0.4000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s - loss: 1.0028 - acc: 0.4000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s - loss: 0.9806 - acc: 0.4000\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s - loss: 0.9592 - acc: 0.4000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s - loss: 0.9382 - acc: 0.4000\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s - loss: 0.9179 - acc: 0.4000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s - loss: 0.8983 - acc: 0.4000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s - loss: 0.8795 - acc: 0.4000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s - loss: 0.8613 - acc: 0.4000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s - loss: 0.8437 - acc: 0.4000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s - loss: 0.8275 - acc: 0.4000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s - loss: 0.8118 - acc: 0.3000\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s - loss: 0.7967 - acc: 0.3000\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s - loss: 0.7822 - acc: 0.3000\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s - loss: 0.7686 - acc: 0.3000\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s - loss: 0.7558 - acc: 0.2000\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s - loss: 0.7437 - acc: 0.2000\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s - loss: 0.7323 - acc: 0.1000\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s - loss: 0.7216 - acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s - loss: 0.7116 - acc: 0.2000\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s - loss: 0.7021 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s - loss: 0.6850 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s - loss: 0.6774 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s - loss: 0.6703 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s - loss: 0.6637 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s - loss: 0.6575 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s - loss: 0.6518 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s - loss: 0.6465 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s - loss: 0.6415 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s - loss: 0.6370 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s - loss: 0.6327 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s - loss: 0.6287 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s - loss: 0.6250 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s - loss: 0.6216 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s - loss: 0.6183 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s - loss: 0.6153 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s - loss: 0.6124 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s - loss: 0.6097 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s - loss: 0.6071 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s - loss: 0.6046 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s - loss: 0.6022 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s - loss: 0.5999 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s - loss: 0.5977 - acc: 0.5000\n",
      "[[ 0.58425069]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지를 불러옵니다.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# 시퀀스 모델을 생성합니다.\n",
    "model = Sequential()\n",
    "\n",
    "# 생성한 시퀀스 모델에 3개 레이어를 쌓습니다. \n",
    "model.add(Dense(16, input_dim=1, activation='relu')) # 입력이 숫자 하나이고 출력이 6개인 레이어입니다.\n",
    "model.add(Dense(32, activation='relu')) # 입력이 숫자 하나이고 출력이 6개인 레이어입니다.\n",
    "model.add(Dense(1, activation='sigmoid')) # 입력이 8개이고 출력이 1개인 레이어입니다.\n",
    "\n",
    "# 모델을 학습시키기 위해 목표함수와 최적화기를 구성합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# X, Y를 준비합니다.\n",
    "X = np.array([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]) # 숫자 0에서 9까지의 문제 준비\n",
    "#X_onehot = np_utils.to_categorical(X)\n",
    "\n",
    "Y = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1]]) # 숫자 1에서 10까지의 정답 준비, 홀수는 0, 짝수는 1\n",
    "\n",
    "# 모델을 X, Y로 학습시킵니다.\n",
    "model.fit(X, Y, epochs=50, batch_size=10)\n",
    "\n",
    "X_hat = np.array([[2]]) # numpy 패키지를 이용해서 숫자 '3'인 입력을 하나 만듭니다.\n",
    "#X_hat_onehot = np_utils.to_categorical(X_hat, num_classes=10)\n",
    "\n",
    "Y_hat = model.predict(X_hat)#_onehot) # 앞서 만든 숫자 '3'을 모델의 네트워크에 입력한 뒤 계산된 출력값을 y_hat에 저장합니다.\n",
    "\n",
    "print(Y_hat) # y_hat을 화면에 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 필요한 패키지를 불러옵니다.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# 시퀀스 모델을 생성합니다.\n",
    "model = Sequential()\n",
    "\n",
    "# 생성한 시퀀스 모델에 3개 레이어를 쌓습니다. \n",
    "model.add(Dense(16, input_dim=10, activation='relu')) # 입력이 숫자 하나이고 출력이 6개인 레이어입니다.\n",
    "model.add(Dense(32, activation='relu')) # 입력이 숫자 하나이고 출력이 6개인 레이어입니다.\n",
    "model.add(Dense(1, activation='sigmoid')) # 입력이 8개이고 출력이 1개인 레이어입니다.\n",
    "\n",
    "# 모델을 학습시키기 위해 목표함수와 최적화기를 구성합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# X, Y를 준비합니다.\n",
    "X = np.array([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]) # 숫자 0에서 9까지의 문제 준비\n",
    "X_onehot = np_utils.to_categorical(X)\n",
    "\n",
    "Y = np.array([[0], [1], [0], [1], [0], [1], [0], [1], [0], [1]]) # 숫자 1에서 10까지의 정답 준비, 홀수는 0, 짝수는 1\n",
    "\n",
    "# 모델을 X, Y로 학습시킵니다.\n",
    "model.fit(X_onehot, Y, epochs=50, batch_size=10)\n",
    "\n",
    "X_hat = np.array([[2]]) # numpy 패키지를 이용해서 숫자 '3'인 입력을 하나 만듭니다.\n",
    "X_hat_onehot = np_utils.to_categorical(X_hat, num_classes=10)\n",
    "\n",
    "Y_hat = model.predict(X_hat_onehot) # 앞서 만든 숫자 '3'을 모델의 네트워크에 입력한 뒤 계산된 출력값을 y_hat에 저장합니다.\n",
    "\n",
    "print(Y_hat) # y_hat을 화면에 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s - loss: 0.7387 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s - loss: 0.7362 - acc: 0.4000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s - loss: 0.7335 - acc: 0.4000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s - loss: 0.7306 - acc: 0.4000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s - loss: 0.7277 - acc: 0.4000\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s - loss: 0.7247 - acc: 0.4000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s - loss: 0.7216 - acc: 0.4000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s - loss: 0.7187 - acc: 0.4000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s - loss: 0.7158 - acc: 0.4000\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s - loss: 0.7129 - acc: 0.4000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s - loss: 0.7101 - acc: 0.4000\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s - loss: 0.7074 - acc: 0.3000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s - loss: 0.7046 - acc: 0.3000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s - loss: 0.7020 - acc: 0.2000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s - loss: 0.6993 - acc: 0.1000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s - loss: 0.6967 - acc: 0.1000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s - loss: 0.6942 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s - loss: 0.6917 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s - loss: 0.6892 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s - loss: 0.6868 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s - loss: 0.6844 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s - loss: 0.6820 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s - loss: 0.6797 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s - loss: 0.6775 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s - loss: 0.6752 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s - loss: 0.6730 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s - loss: 0.6708 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s - loss: 0.6686 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s - loss: 0.6665 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s - loss: 0.6644 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s - loss: 0.6624 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s - loss: 0.6604 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s - loss: 0.6584 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s - loss: 0.6564 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s - loss: 0.6545 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s - loss: 0.6526 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s - loss: 0.6508 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s - loss: 0.6489 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s - loss: 0.6471 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s - loss: 0.6453 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s - loss: 0.6435 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s - loss: 0.6418 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s - loss: 0.6401 - acc: 0.6000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s - loss: 0.6384 - acc: 0.6000\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s - loss: 0.6367 - acc: 0.6000\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s - loss: 0.6351 - acc: 0.6000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s - loss: 0.6335 - acc: 0.6000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s - loss: 0.6319 - acc: 0.6000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s - loss: 0.6303 - acc: 0.6000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s - loss: 0.6288 - acc: 0.6000\n",
      "[[ 0.51327342]]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지를 불러옵니다.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "X = np.array([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]])\n",
    "Y = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1]])\n",
    "#X = np_utils.to_categorical(X)\n",
    "model.fit(X, Y, epochs=50, batch_size=10)\n",
    "X_hat = np.array([[1]])\n",
    "#X_hat = np_utils.to_categorical(X_hat, num_classes=10)\n",
    "Y_hat = model.predict(X_hat)\n",
    "print(Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s - loss: 0.7181 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s - loss: 0.6408 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s - loss: 0.6016 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s - loss: 0.5825 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s - loss: 0.5741 - acc: 0.6000\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s - loss: 0.5723 - acc: 0.6000\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s - loss: 0.5731 - acc: 0.6000\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s - loss: 0.5730 - acc: 0.6000\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s - loss: 0.5707 - acc: 0.6000\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s - loss: 0.5663 - acc: 0.6000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s - loss: 0.5601 - acc: 0.6000\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s - loss: 0.5547 - acc: 0.6000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s - loss: 0.5513 - acc: 0.6000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s - loss: 0.5496 - acc: 0.6000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s - loss: 0.5481 - acc: 0.6000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s - loss: 0.5446 - acc: 0.6000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s - loss: 0.5397 - acc: 0.6000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s - loss: 0.5342 - acc: 0.6000\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s - loss: 0.5295 - acc: 0.7000\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s - loss: 0.5254 - acc: 0.7000\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s - loss: 0.5213 - acc: 0.7000\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s - loss: 0.5171 - acc: 0.7000\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s - loss: 0.5120 - acc: 0.7000\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s - loss: 0.5062 - acc: 0.7000\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s - loss: 0.4998 - acc: 0.7000\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s - loss: 0.4925 - acc: 0.7000\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s - loss: 0.4854 - acc: 0.7000\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s - loss: 0.4779 - acc: 0.8000\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s - loss: 0.4690 - acc: 0.8000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s - loss: 0.4585 - acc: 0.8000\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s - loss: 0.4467 - acc: 0.8000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s - loss: 0.4339 - acc: 0.8000\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s - loss: 0.4198 - acc: 0.8000\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s - loss: 0.4033 - acc: 0.8000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s - loss: 0.3872 - acc: 0.9000\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s - loss: 0.3696 - acc: 0.9000\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s - loss: 0.3504 - acc: 0.9000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s - loss: 0.3322 - acc: 0.9000\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s - loss: 0.3131 - acc: 0.9000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s - loss: 0.2944 - acc: 0.9000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s - loss: 0.2744 - acc: 0.9000\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s - loss: 0.2536 - acc: 0.9000\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s - loss: 0.2335 - acc: 0.9000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s - loss: 0.2138 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s - loss: 0.1943 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s - loss: 0.1762 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s - loss: 0.1593 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s - loss: 0.1439 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s - loss: 0.1289 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s - loss: 0.1161 - acc: 1.0000\n",
      "[[ 0.99608624]]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지를 불러옵니다.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=1, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "X = np.array([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]])\n",
    "Y = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1]])\n",
    "#X = np_utils.to_categorical(X)\n",
    "model.fit(X, Y, epochs=50, batch_size=10)\n",
    "X_hat = np.array([[8]])\n",
    "#X_hat = np_utils.to_categorical(X_hat, num_classes=10)\n",
    "Y_hat = model.predict(X_hat)\n",
    "print(Y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고 사람 머리의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고 사람 상반신의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고 사람 하반신의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고사람으로 기본모델 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 레고사람으로 GAN 모델 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 사소한 변화를 무시해주는 맥스풀링(Max Pooling) 레이어\n",
    "\n",
    "컨볼루션 레이어의 출력 이미지에서 주요값만 뽑아 크기가 작은 출력 영상을 만듭니다. 이것은 지역적인 사소한 변화가 영향을 미치지 않도록 합니다. \n",
    "\n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "주요 인자는 다음과 같습니다.\n",
    "* pool_size : 수직, 수평 축소 비율을 지정합니다. (2, 2)이면 출력 영상 크기는 입력 영상 크기의 반으로 줄어듭니다.\n",
    "\n",
    "예를 들어, 입력 영상 크기가 4 x 4이고, 풀 크기를 (2, 2)로 했을 때를 도식화하면 다음과 같습니다. 녹색 블록은 입력 영상을 나타내고, 노란색 블록은 풀 크기에 따라 나눈 경계를 표시합니다. 해당 풀에서 가장 큰 값을 선택하여 파란 블록으로 만들면, 그것이 출력 영상이 됩니다. 가장 오른쪽은 맥스풀링 레이어를 약식으로 표시한 것입니다.\n",
    "\n",
    "![lego_12](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_12.png)\n",
    "\n",
    "이 레이어는 영상의 작은 변화라던지 사소한 움직임이 특징을 추출할 때 크게 영향을 미치지 않도록 합니다. 영상 내에 특징이 세 개가 있다고 가정했을 때, 아래 그림에서 첫 번째 영상을 기준으로 두 번째 영상은 오른쪽으로 이동하였고, 세 번째 영상은 약간 비틀어 졌고, 네 번째 영상은 조금 확대되었지만, 맥스풀링한 결과는 모두 동일합니다. 얼굴 인식 문제를 예를 들면, 맥스풀링의 역할은 사람마다 눈, 코, 입 위치가 조금씩 다른데 이러한 차이가 사람이라고 인식하는 데 있어서는 큰 영향을 미치지 않게 합니다.\n",
    "\n",
    "![lego_13](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 영상을 일차원으로 바꿔주는 플래튼(Flatten) 레이어\n",
    "\n",
    "CNN에서 컨볼루션 레이어나 맥스풀링 레이어를 반복적으로 거치면 주요 특징만 추출되고, 추출된 주요 특징은 전결합층에 전달되어 학습됩니다. 컨볼루션 레이어나 맥스풀링 레이어는 주로 2차원 자료를 다루지만 전결합층에 전달하기 위해선 1차원 자료로 바꿔줘야 합니다. 이 때 사용되는 것이 플래튼 레이어입니다. 사용 예시는 다음과 같습니다.\n",
    "\n",
    "    Flatten()\n",
    "    \n",
    "이전 레이어의 출력 정보를 이용하여 입력 정보를 자동으로 설정되며, 출력 형태는 입력 형태에 따라 자동으로 계산되기 때문에 별도로 사용자가 파라미터를 지정해주지 않아도 됩니다. 크기가 3 x 3인 영상을 1차원으로 변경했을 때는 도식화하면 다음과 같습니다.\n",
    "\n",
    "![lego_14](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 한 번 쌓아보기\n",
    "\n",
    "지금까지 알아본 레이어를 이용해서 간단한 컨볼루션 신경망 모델을 만들어보겠습니다. 먼저 간단한 문제를 정의해봅시다. 손으로 삼각형, 사각형, 원을 손으로 그린 이미지가 있고 이미지 크기가 8 x 8이라고 가정해봅니다. 삼각형, 사각형, 원을 구분하는 3개의 클래스를 분류하는 문제이기 때문에 출력 벡터는 3개여야 합니다. 필요하다고 생각하는 레이어를 구성해봤습니다.\n",
    "\n",
    "![lego_22](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_22.png)\n",
    "\n",
    "* 컨볼루션 레이어 : 입력 이미지 크기 8 x 8, 입력 이미지 채널 1개, 필터 크기 3 x 3, 필터 수 2개, 경계 타입 'same', 활성화 함수 'relu'\n",
    "\n",
    "![lego_15](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_15.png)\n",
    "\n",
    "* 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "\n",
    "![lego_16](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_16.png)\n",
    "\n",
    "* 컨볼루션 레이어 : 입력 이미지 크기 4 x 4, 입력 이미지 채널 2개, 필터 크기 2 x 2, 필터 수 3개, 경계 타입 'same', 활성화 함수 'relu'\n",
    "\n",
    "![lego_17](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_17.png)\n",
    "\n",
    "* 맥스풀링 레이어 : 풀 크기 2 x 2\n",
    "\n",
    "![lego_18](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_18.png)\n",
    "\n",
    "* 플래튼 레이어\n",
    "\n",
    "![lego_19](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_19.png)\n",
    "\n",
    "* 댄스 레이어 : 입력 뉴런 수 12개, 출력 뉴런 수 8개, 활성화 함수 'relu'\n",
    "\n",
    "![lego_20](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_20.png)\n",
    "\n",
    "* 댄스 레이어 : 입력 뉴런 수 8개, 출력 뉴런 수 3개, 활성화 함수 'softmax'\n",
    "\n",
    "![lego_21](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_21.png)\n",
    "\n",
    "모든 레이어 블록이 준비되었으니 이를 조합해 봅니다. 입출력 크기만 맞으면 블록 끼우듯이 합치면 됩니다. 참고로 케라스 코드에서는 가장 첫번째 레이어를 제외하고는 입력 형태를 자동으로 계산하므로 이 부분은 신경쓰지 않아도 됩니다. 레이어를 조립하니 간단한 컨볼루션 모델이 생성되었습니다. 이 모델에 이미지를 입력하면, 삼각형, 사각형, 원을 나타내는 벡터가 출력됩니다.\n",
    "\n",
    "![lego_23](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_lego_23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 케라스 코드로 어떻게 구현하는 지 알아봅니다. 먼저 필요한 패키지를 추가하는 과정입니다. 케라스의 레이어는 'keras.layers'에 정의되어 있으며, 여기서 필요한 레이어를 추가합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential 모델을 하나 생성한 뒤 위에서 정의한 레이어를 차례차레 추가하면 컨볼루션 모델이 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), padding='same', activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(3, (2, 2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성한 모델을 케라스에서 제공하는 함수를 이용하여 가시화 시켜봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](http://tykimos.github.io/warehouse/2017-1-27_CNN_Layer_Talk_model.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 요약\n",
    "\n",
    "컨볼루션 신경망 모델에서 사용되는 주요 레이어의 원리와 역할에 대해서 알아보았고 레이어를 조합하여 간단한 컨볼루션 신경망 모델을 만들어봤습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/lecture/)\n",
    "* 이전 : [딥러닝 이야기/다층 퍼셉트론 모델 만들어보기](https://tykimos.github.io/2017/02/04/MLP_Getting_Started/)\n",
    "* 다음 : [딥러닝 이야기/컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/2017/03/08/CNN_Getting_Started/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
