{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 데이터셋 생성기\n",
    "\n",
    "모델을 훈련시키기 위한 데이터셋을 생성한다. 데이터셋을 생성하기 위해, 원본 데이터 전처리를 레벨별로 수행한다.\n",
    "\n",
    "Raw : 원본 데이터  \n",
    "Level 0 : 패치 이미지를 추출하기 위해 원본 데이터를 가공함  \n",
    "Level 1 : 패치 이미지를 추출하여 폴더별로 정리함  \n",
    "Level 2 : Upsampling 또는 downsampling 수행  \n",
    "Dataset : 모델 입력 데이터 (IMAGE와 LABEL로 구성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 경로를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEVEL1_TRUE_DATA_DIR = './warehouse/level1/train/true/'\n",
    "LEVEL1_FALSE_DATA_DIR = './warehouse/level1/train/false/'\n",
    "\n",
    "LEVEL2_TRUE_DATA_DIR = './warehouse/level2/train/true/'\n",
    "LEVEL2_FALSE_DATA_DIR = './warehouse/level2/train/false/'\n",
    "\n",
    "DATASET_IMAGE_PATH = './dataset/train_image_64x64_gray_447648.bin'\n",
    "DATASET_LABEL_PATH = './dataset/train_label_64x64_gray_447648.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경설정된 경로가 없다면 폴더를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchGenerator():\n",
    "\n",
    "    def __init__(self, num_patch_channel, num_patch_row, num_patch_col, num_sample_per_batch, num_batch_per_cache):        \n",
    "        self.num_patch_channel = num_patch_channel # channel 수\n",
    "        self.num_patch_row = num_patch_row # row 수\n",
    "        self.num_patch_col = num_patch_col # col 수 \n",
    "        self.num_sample_per_batch = num_sample_per_batch # 한 배치 당 샘플 수\n",
    "        self.num_batch_per_cache = num_batch_per_cache # 한 캐쉬 당 배치 수\n",
    "        \n",
    "    def upsampling_rotate(self, angle):\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def sample_size(self):\n",
    "        return self.num_patch_channel * self.num_patch_row * self.num_patch_col\n",
    "    \n",
    "    def batch_size(self):\n",
    "        return self.num_sample_per_batch * self.sample_size()\n",
    "    \n",
    "    def cache_size(self):\n",
    "        return self.num_batch_per_cache * self.batch_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PrintProgress(prev_percent, curr_percent):\n",
    "    \n",
    "    if prev_percent % 5 == curr_percent % 5:\n",
    "        return None\n",
    "    \n",
    "    if curr_percent % 10 == 0:\n",
    "        sys.stdout.write(str(curr_percent) + '%')\n",
    "        sys.stdout.flush()\n",
    "    else:\n",
    "        if curr_percent % 5 == 0:\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GetLevelDataList() : Level 경로에서 파일 목록을 가지고 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetLevelDataList(dir_path):\n",
    "\n",
    "    level_data_list = []\n",
    "    \n",
    "    for (path, dir, files) in os.walk(dir_path):\n",
    "        for filename in files:\n",
    "            ext = os.path.splitext(filename)[-1]\n",
    "            if ext == '.bmp' or ext == '.png' or ext == '.jpg' or ext == '.jpeg':\n",
    "                level_data_list.append(dir_path + filename)\n",
    "                    \n",
    "    return level_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RotatePatchImage() : 업샘플링을 위해 패치이미지를 회전시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RotatePatchImage(src_file_list, dst_dir):\n",
    "    \n",
    "    total_count = len(src_file_list)\n",
    "    curr_count = 0\n",
    "    prev_percent = -1\n",
    "    \n",
    "    for file_path in src_file_list:\n",
    "        cv_img = cv2.imread(file_path)\n",
    "        (h, w) = cv_img.shape[:2]\n",
    "\n",
    "        check = 'f'\n",
    "        \n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        if filename.rfind('t.png') != -1:\n",
    "            check = 't'\n",
    "\n",
    "        for angle in range(0,360,15):\n",
    "            M = cv2.getRotationMatrix2D((w/2, h/2), angle, scale=1.0)\n",
    "            rotated = cv2.warpAffine(cv_img, M, (w, h))\n",
    "            dst_file_path = dst_dir + filename[:filename.rfind('.')] + '_' + str(angle) + check + '.png'\n",
    "            cv2.imwrite(dst_file_path, rotated)\n",
    "\n",
    "        curr_percent = int(curr_count*100/total_count)\n",
    "        PrintProgress(prev_percent, curr_percent)\n",
    "        curr_count = curr_count + 1\n",
    "        prev_percent = curr_percent\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShufflePatchImage() : 패치 이미지를 합치고 섞습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ShufflePatchImage(true_data_list, false_data_list):\n",
    "\n",
    "    random.shuffle(true_data_list)\n",
    "    random.shuffle(false_data_list)\n",
    "\n",
    "    shuffled_data_list = true_data_list + false_data_list\n",
    "    \n",
    "    random.shuffle(shuffled_data_list)\n",
    "    \n",
    "    return shuffled_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GenerateDataset() : 데이터셋을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GenerateDataset(data_list, out_image_file_path, out_label_file_path):\n",
    "    \n",
    "    total_count = len(data_list)\n",
    "    curr_count = 0\n",
    "    prev_percent = -1\n",
    "    \n",
    "    fp_label = open(out_label_file_path, 'wb')\n",
    "    fp_image = open(out_image_file_path, 'wb')\n",
    "        \n",
    "    for data_item in data_list:\n",
    "        cv_img = cv2.imread(data_item)\n",
    "        cv_gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        label = '0'\n",
    "        if data_item.find(\"t.\") != -1:\n",
    "            label = '1'\n",
    "\n",
    "        fp_label.write(label)\n",
    "        fp_image.write(cv_gray.tobytes())\n",
    "\n",
    "        \"\"\"\n",
    "        for row in cv_gray:  \n",
    "            for val in row:\n",
    "                fp_image.write(val)\n",
    "        \"\"\"\n",
    "\n",
    "        curr_count = curr_count + 1\n",
    "        curr_percent = int(curr_count*100/total_count)\n",
    "        PrintProgress(prev_percent, curr_percent)\n",
    "        prev_percent = curr_percent\n",
    "\n",
    "    fp_label.close()\n",
    "    fp_image.close()\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level2 true data count :\t93120\n",
      "level2 false data count :\t354528\n",
      "merge and shuffle level 2 patch image...\n",
      "generate dataset...\n",
      "0%.10%.20%.30%.40%.50%.60%.70%.80%.90%.100%\n",
      "dataset pacth image : \t./dataset/train_image_64x64_gray_447648.bin_2\n",
      "dataset label : \t./dataset/train_label_64x64_gray_447648.bin_2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \"\"\"\n",
    "    PatchGenerator pg\n",
    "    \n",
    "    pg.init(positive_dir_path, negative_dir_path)\n",
    "    pg.upsampling_rotate(val)\n",
    "    pg.upsampling_noise(...)\n",
    "    pg.upsampling_shift(...)\n",
    "    pg.upsampling_zoom(...)\n",
    "    pg.upsampling_horizontal_flip(...)\n",
    "    pg.upsampling_vertical_flip(...)    \n",
    "    pg.generate_dataset(patch_file_path, label_file_path)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Level1 데이터 목록 가져오기\n",
    "    level1_true_data_list = GetLevelDataList(LEVEL1_TRUE_DATA_DIR)\n",
    "    level1_false_data_list = GetLevelDataList(LEVEL1_FALSE_DATA_DIR)\n",
    "    \n",
    "    print('level1 true data count :\\t' + str(len(level1_true_data_list)))\n",
    "    print('level1 false data count :\\t' + str(len(level1_false_data_list)))    \n",
    "    \n",
    "    # Level1 데이터로부터 Level2 데이터 생성\n",
    "    \n",
    "    print('generate level2 true data...')\n",
    "    \n",
    "    RotatePatchImage(level1_true_data_list, # Level 1 파일 목록 (in)\n",
    "                     LEVEL2_TRUE_DATA_DIR) # Level 2 경로 (out)\n",
    "\n",
    "    print('generate level2 false data...')\n",
    "    \n",
    "    RotatePatchImage(level1_false_data_list, # Level 1 파일 목록 (in)\n",
    "                     LEVEL2_FALSE_DATA_DIR) # Level 2 경로 (out)\n",
    "\n",
    "     \n",
    "    # Level2 데이터 목록 가져오기\n",
    "\n",
    "    level2_true_data_list = GetLevelDataList(LEVEL2_TRUE_DATA_DIR)\n",
    "    level2_false_data_list = GetLevelDataList(LEVEL2_FALSE_DATA_DIR)\n",
    "\n",
    "    print('level2 true data count :\\t' + str(len(level2_true_data_list)))\n",
    "    print('level2 false data count :\\t' + str(len(level2_false_data_list)))    \n",
    "    \n",
    "    # Level2 데이터로부터 Dataset 생성\n",
    "\n",
    "    print('merge and shuffle level 2 patch image...')\n",
    "    merge_shuffle_level2_data_list = ShufflePatchImage(level2_true_data_list, level2_false_data_list)\n",
    "      \n",
    "    print('generate dataset...')\n",
    "    GenerateDataset(merge_shuffle_level2_data_list, DATASET_IMAGE_PATH, DATASET_LABEL_PATH)\n",
    "    \n",
    "    print('dataset pacth image : \\t' + DATASET_IMAGE_PATH)    \n",
    "    print('dataset label : \\t' + DATASET_LABEL_PATH)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
