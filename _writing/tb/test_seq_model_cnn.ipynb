{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 객담도말 결핵진단 딥러닝 모델\n",
    "\n",
    "CNN 기반의 객담도말 결핵진단 딥러닝 모델 소스코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'myGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dcc0e5bbae73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'myGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution1D, Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(1, img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "\n",
    "model.fit_generator(myGenerator(), samples_per_epoch = 60000, nb_epoch = 2, verbose=2, show_accuracy=True, callbacks=[], validation_data=None, class_weight=None, nb_worker=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 660 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델관련 환경설정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # 한 epoch에서 실행시키는 단위(배치)크기\n",
    "NUM_CLASSES = 2 # 클래스 수\n",
    "NUM_EPOCHS = 1 # epoch 수\n",
    "NUM_FILTERS = 32 # convolution 필터 수\n",
    "NUM_POOL = 2 # max plling을 위한 pooling 영역 크기\n",
    "NUM_CONV = 3 # convolution 커널 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 관련 환경설정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_CHANNELS = 1\n",
    "IMG_ROWS = 64\n",
    "IMG_COLS = 64\n",
    "\n",
    "TRAIN_DATA_COUNT = 447648\n",
    "\n",
    "train_img_filename = './dataset/train_image_64x64_gray_447648.bin'\n",
    "train_label_filename = './dataset/train_label_64x64_gray_447648.bin'\n",
    "\n",
    "TEST_DATA_COUNT = 15873\n",
    "\n",
    "test_img_filename = './dataset/test_image_64x64_gray_15873.bin'\n",
    "test_label_filename = './dataset/test_label_64x64_gray_15873.bin'\n",
    "\n",
    "VALIDATION_DATA_COUNT = int(TRAIN_DATA_COUNT * 1.0/4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_FILE_PATH = './seq_model_cnn.h5'\n",
    "PREDICT_FILE_PATH = './predict.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img 자료 로딩 함수 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(filename, count, channel, row, col):\n",
    "    print('Loading data from', filename)\n",
    "\n",
    "    print('file size : ', os.path.getsize(filename))\n",
    "    print('calc size : ', count * channel * row * col)\n",
    "    \n",
    "    fp = open(filename, 'rb')\n",
    "    buf = fp.read(count * channel * row * col)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8)\n",
    "    data = data.reshape(count, channel, row, col)\n",
    "\n",
    "    print('loaded shape : ', data.shape)\n",
    "\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label 자료 로딩함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_label(filename, count, classes):\n",
    "    print('Loading labels from ', filename)\n",
    "    \n",
    "    print('file size : ', os.path.getsize(filename))\n",
    "    print('calc size : ', count)\n",
    "    \n",
    "    fp = open(filename, 'r')\n",
    "    buf = fp.read(count)\n",
    "        \n",
    "    data_bin = []\n",
    "    for i in buf:\n",
    "        data_bin.append(i)\n",
    "    data = np.asarray(data_bin, dtype=np.uint8, order='C')\n",
    "\n",
    "    print('loaded shape : ', data.shape)\n",
    "    \n",
    "    label_hist = np.histogram(data, bins=range(NUM_CLASSES+1))\n",
    "    print(label_hist)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    data = np_utils.to_categorical(data, classes)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./dataset/train_image_64x64_gray_447648.bin\n",
      "file size :  1833566208\n",
      "calc size :  1833566208\n",
      "loaded shape :  (447648, 1, 64, 64)\n",
      "Loading data from ./dataset/test_image_64x64_gray_15873.bin\n",
      "file size :  65015808\n",
      "calc size :  65015808\n",
      "loaded shape :  (15873, 1, 64, 64)\n",
      "Loading labels from  ./dataset/train_label_64x64_gray_447648.bin\n",
      "file size :  447648\n",
      "calc size :  447648\n",
      "loaded shape :  (447648,)\n",
      "(array([354528,  93120]), array([0, 1, 2]))\n",
      "Loading labels from  ./dataset/test_label_64x64_gray_15873.bin\n",
      "file size :  15873\n",
      "calc size :  15873\n",
      "loaded shape :  (15873,)\n",
      "(array([15520,   353]), array([0, 1, 2]))\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "train_img = load_img(train_img_filename, TRAIN_DATA_COUNT, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "test_img = load_img(test_img_filename, TEST_DATA_COUNT, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "#validation_img = load_img(validation_img_filename, VALIDATION_DATA_COUNT, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "\n",
    "train_label = load_label(train_label_filename, TRAIN_DATA_COUNT, NUM_CLASSES)\n",
    "test_label = load_label(test_label_filename, TEST_DATA_COUNT, NUM_CLASSES)\n",
    "#validation_label = load_label(validation_label_filename, VALIDATION_DATA_COUNT, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 일부로부터 검증셋을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count : 335736\n",
      "validation count : 111912\n"
     ]
    }
   ],
   "source": [
    "validation_img = train_img[:VALIDATION_DATA_COUNT, ...]\n",
    "validation_label = train_label[:VALIDATION_DATA_COUNT, ...]\n",
    "\n",
    "train_img = train_img[VALIDATION_DATA_COUNT:, ...]\n",
    "train_label = train_label[VALIDATION_DATA_COUNT:, ...]\n",
    "\n",
    "print('train count : ' + str(len(train_img)))\n",
    "print('validation count : ' + str(len(validation_img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥리닝 모델을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Convolution2D(NUM_FILTERS, NUM_CONV, NUM_CONV,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(IMG_CHANNELS, IMG_ROWS, IMG_COLS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(NUM_FILTERS, NUM_CONV, NUM_CONV))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(NUM_POOL, NUM_POOL)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# np_utils.visualize_util.plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'callbacks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-008e9efc302a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mprintbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'callbacks' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def myGenerator():\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    y_train = np_utils.to_categorical(y_train,10)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    while 1:\n",
    "        for i in range(1875): # 1875 * 32 = 60000 -> # of training samples\n",
    "            print(\"[\")\n",
    "            if i%125==0:\n",
    "                print \"i = \" + str(i)\n",
    "            yield X_train[i*32:(i+1)*32], y_train[i*32:(i+1)*32]\n",
    "            print(\"]\")\n",
    "        print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 335736 samples, validate on 111912 samples\n",
      "Epoch 1/1\n",
      "335736/335736 [==============================] - 310s - loss: 0.1833 - acc: 0.9235 - val_loss: 0.1511 - val_acc: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab26644190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_img, \n",
    "          train_label, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          nb_epoch=NUM_EPOCHS,\n",
    "          verbose=1, \n",
    "          validation_data=(validation_img, validation_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델 테스트를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15873/15873 [==============================] - 4s     \n",
      "Test score: 0.0604064624439\n",
      "Test accuracy: 0.97668997669\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_img, test_label, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15873/15873 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "classes = model.predict_classes(test_img, batch_size=32)\n",
    "np.savetxt(PREDICT_FILE_PATH, classes, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 32, 62, 62)  320         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 32, 62, 62)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 32, 60, 60)  9248        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 32, 60, 60)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 32, 30, 30)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 32, 30, 30)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 28800)       0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 128)         3686528     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 128)         0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 128)         0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 2)           258         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 2)           0           dense_2[0][0]                    "
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save_weights(MODEL_SAVE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
