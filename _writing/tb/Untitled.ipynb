{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : 한 배치 당 패치 수\t32\n",
      "B : 한 캐쉬 당 배치 수\t64\n",
      "C = A x B : 한 캐쉬 당 패치 수\t2048\n",
      "D : 한 패치 당 바이트 수\t4096\n",
      "E = A x D : 한 배치 당 바이트 수\t131072\n",
      "F = E x B : 한 캐쉬 당 바이트 수\t8388608, 8192KB\n",
      "훈련 데이터 수\t335736\n",
      "훈련 배치 수\t10491\n",
      "훈련 캐쉬 수\t164\n",
      "검증 데이터 수\t111912\n",
      "검증 배치 수\t3497\n",
      "검증 캐쉬 수\t55\n"
     ]
    }
   ],
   "source": [
    "IMG_CHANNELS = 1\n",
    "IMG_ROWS = 64\n",
    "IMG_COLS = 64\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "NUM_SAMPLES = 447648\n",
    "BATCH_SIZE = 32 # 한 epoch에서 실행시키는 단위(배치)크기\n",
    "CACHE_BATCH_COUNT = 64\n",
    "\n",
    "sample_bytes = IMG_CHANNELS * IMG_ROWS * IMG_COLS\n",
    "batch_bytes = sample_bytes * BATCH_SIZE\n",
    "cache_bytes = batch_bytes * CACHE_BATCH_COUNT\n",
    "\n",
    "validation_num_samples = int(NUM_SAMPLES*1.0/4.0)\n",
    "train_num_samples = NUM_SAMPLES - validation_num_samples\n",
    "\n",
    "train_total_batch_count = train_num_samples / BATCH_SIZE\n",
    "train_total_cache_count = (train_total_batch_count + (CACHE_BATCH_COUNT-1)) / CACHE_BATCH_COUNT\n",
    "\n",
    "validation_total_batch_count = validation_num_samples / BATCH_SIZE\n",
    "validation_total_cache_count = (validation_total_batch_count + (CACHE_BATCH_COUNT-1)) / CACHE_BATCH_COUNT\n",
    "\n",
    "# index 기준은 batch 수\n",
    "print('A : 한 배치 당 패치 수\\t' + str(BATCH_SIZE))\n",
    "print('B : 한 캐쉬 당 배치 수\\t' + str(CACHE_BATCH_COUNT))\n",
    "print('C = A x B : 한 캐쉬 당 패치 수\\t' + str(BATCH_SIZE*CACHE_BATCH_COUNT))\n",
    "print('D : 한 패치 당 바이트 수\\t' + str(sample_bytes))\n",
    "print('E = A x D : 한 배치 당 바이트 수\\t' + str(batch_bytes))\n",
    "print('F = E x B : 한 캐쉬 당 바이트 수\\t' + str(cache_bytes) + ', ' + str(cache_bytes/1024) + 'KB')\n",
    "\n",
    "# train\n",
    "print('훈련 데이터 수\\t' + str(train_num_samples))\n",
    "print('훈련 배치 수\\t' + str(train_total_batch_count))\n",
    "print('훈련 캐쉬 수\\t' + str(train_total_cache_count))\n",
    "\n",
    "# validataion\n",
    "print('검증 데이터 수\\t' + str(validation_num_samples))\n",
    "print('검증 배치 수\\t' + str(validation_total_batch_count))\n",
    "print('검증 캐쉬 수\\t' + str(validation_total_cache_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TrainDatasetGenerator():\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    # x는 패치, y는 라벨\n",
    "    fp_x = open('./dataset/train_image_64x64_gray_447648.bin', 'rb')\n",
    "    fp_y = open('./dataset/train_label_64x64_gray_447648.bin', 'rb')\n",
    "\n",
    "    offset_start_x = 0\n",
    "    offset_start_y = 0\n",
    "    \n",
    "    # for문 구조\n",
    "    # 전체 캐쉬수 만큼 루프\n",
    "    for idx_cache in range(train_total_cache_count):\n",
    "\n",
    "        # 해당 캐쉬 당 배치 수 계산 (마지막 캐쉬의 배치 수 계산 고려)\n",
    "        if ((idx_cache + 1) * cache_batch_count) > train_total_batch_count:\n",
    "            batch_count = train_total_batch_count - idx_cache * cache_batch_count\n",
    "        else:\n",
    "            batch_count = cache_batch_count\n",
    "\n",
    "        # y인 경우에는 패치당 1바이트이므로 캐쉬당 패치수로 인덱스를 계산함            \n",
    "        offset_x = offset_start_x + idx_cache * cache_bytes\n",
    "        offset_y = offset_start_y + idx_cache * CACHE_BATCH_COUNT * BATCH_SIZE\n",
    "\n",
    "        # 현재 캐쉬에서 읽어야 할 바이트 수는 배치 수 x 배치 바이트 만큼임\n",
    "        read_cache_bytes = batch_bytes * batch_count\n",
    "\n",
    "        fp_x.seek(offset_x, 1)\n",
    "        fp_y.seek(offset_y, 1)\n",
    "\n",
    "        # 패치 읽음\n",
    "        # 파일에서 데이터를 읽어 캐쉬 버퍼에 로딩\n",
    "        cache_buf_x = fp_x.read(read_cache_bytes)\n",
    "        cache_data_x = np.frombuffer(cache_buf_x, dtype=np.uint8)\n",
    "        cache_data_x = cache_data.reshape(batch_count, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "        cache_data_x = cache_data.astype('float32')\n",
    "        cache_data_x /= 255\n",
    "\n",
    "        # 라벨 읽음\n",
    "        cache_buf_y = fp_y.read(batch_count)\n",
    "        cache_data_y = []\n",
    "        for i in cache_buf_y:\n",
    "            cache_data_y.append(i)\n",
    "        cache_data_y = np.asarray(cache_data_y, dtype=np.uint8, order='C')\n",
    "        # convert class vectors to binary class matrices\n",
    "        cache_data_y = np_utils.to_categorical(cache_data_y, NUM_CLASSES)\n",
    "\n",
    "        # 로딩한 캐쉬에서 배치 수 만큼 루프돌려 해당 배치를 넘겨줌\n",
    "        for idx_batch in range(batch_count):\n",
    "\n",
    "            print (count)\n",
    "            count = count + 1\n",
    "\n",
    "            yield cache_data_x[idx_batch*BATCH_SIZE:(idx_batch+1)*BATCH_SIZE], cache_data_y[idx_batch*BATCH_SIZE:(idx_batch+1)*BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ValidationDatasetGenerator():\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    # x는 패치, y는 라벨\n",
    "    fp_x = open('./dataset/train_image_64x64_gray_447648.bin', 'rb')\n",
    "    fp_y = open('./dataset/train_label_64x64_gray_447648.bin', 'rb')\n",
    "\n",
    "    offset_start_x = train_num_samples * sample_bytes\n",
    "    offset_start_y = train_num_samples\n",
    "    \n",
    "    # for문 구조\n",
    "    # 전체 캐쉬수 만큼 루프\n",
    "    for idx_cache in range(train_total_cache_count):\n",
    "\n",
    "        # 해당 캐쉬 당 배치 수 계산 (마지막 캐쉬의 배치 수 계산 고려)        \n",
    "        if ((idx_cache + 1) * cache_batch_count) > train_total_batch_count:\n",
    "            batch_count = train_total_batch_count - idx_cache * cache_batch_count\n",
    "        else:\n",
    "            batch_count = cache_batch_count\n",
    "\n",
    "        # y인 경우에는 패치당 1바이트이므로 캐쉬당 패치수로 인덱스를 계산함            \n",
    "        offset_x = offset_start_x + idx_cache * cache_bytes\n",
    "        offset_y = offset_start_y + idx_cache * CACHE_BATCH_COUNT * BATCH_SIZE\n",
    "\n",
    "        # 현재 캐쉬에서 읽어야 할 바이트 수는 배치 수 x 배치 바이트 만큼임        \n",
    "        read_cache_bytes = batch_bytes * batch_count\n",
    "\n",
    "        fp_x.seek(offset_x, 1)\n",
    "        fp_y.seek(offset_y, 1)\n",
    "\n",
    "        # 패치 읽음\n",
    "        # 파일에서 데이터를 읽어 캐쉬 버퍼에 로딩\n",
    "        cache_buf_x = fp_x.read(read_cache_bytes)\n",
    "        cache_data_x = np.frombuffer(cache_buf_x, dtype=np.uint8)\n",
    "        cache_data_x = cache_data.reshape(batch_count, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "        cache_data_x = cache_data.astype('float32')\n",
    "        cache_data_x /= 255\n",
    "\n",
    "        # 라벨 읽음        \n",
    "        cache_buf_y = fp_y.read(batch_count)\n",
    "        cache_data_y = []\n",
    "        for i in cache_buf_y:\n",
    "            cache_data_y.append(i)\n",
    "        cache_data_y = np.asarray(cache_data_y, dtype=np.uint8, order='C')\n",
    "        # convert class vectors to binary class matrices\n",
    "        cache_data_y = np_utils.to_categorical(cache_data_y, NUM_CLASSES)\n",
    "\n",
    "        # 로딩한 캐쉬에서 배치 수 만큼 루프돌려 해당 배치를 넘겨줌        \n",
    "        for idx_batch in range(batch_count):\n",
    "\n",
    "            print (count)\n",
    "            count = count + 1\n",
    "\n",
    "            yield cache_data_x[idx_batch*BATCH_SIZE:(idx_batch+1)*BATCH_SIZE], cache_data_y[idx_batch*BATCH_SIZE:(idx_batch+1)*BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "           \n",
    "            buf = fp.read(file_size)\n",
    "            \n",
    "            for batch_it in range(readed_num_mem_batch)\n",
    "                data = np.frombuffer(buf, dtype=np.uint8)\n",
    "                data = data.reshape(count, channel, row, col)\n",
    "\n",
    "            fp_it = fp_it + MEM_BUF_SIZE\n",
    "\n",
    "    print('Loading data from', filepath)\n",
    "\n",
    "    print('file size : ', os.path.getsize(filepath))\n",
    "    print('calc size : ', count * channel * row * col)\n",
    "    \n",
    "    fp = open(filepath, 'rb')\n",
    "    \n",
    "    buf = fp.read(count * channel * row * col)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8)\n",
    "    data = data.reshape(count, channel, row, col)\n",
    "\n",
    "    print('loaded shape : ', data.shape)\n",
    "\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "\n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8794 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "536870912 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8704"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "68 * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while 1:\n",
    "    for f_i in range()\n",
    "    for i in range(20): # 1875 * 32 = 60000 -> # of training samples            \n",
    "        print('i:' + str(i) + ' count:' + str(count))\n",
    "        count = count + 1\n",
    "        print('i*32:' + str(i*32) + '  (i+1)*32:' + str((i+1)*32))\n",
    "        yield X_train[i*32:(i+1)*32], y_train[i*32:(i+1)*32] # 32만큼 전달한다.\n",
    "    print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "640 + 32 + 32 + 32 + 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
