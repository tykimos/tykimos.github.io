{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 객담도말 결핵진단 딥러닝 모델\n",
    "\n",
    "CNN 기반의 객담도말 결핵진단 딥러닝 모델 소스코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델관련 환경설정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # 한 epoch에서 실행시키는 단위(배치)크기\n",
    "NUM_CLASSES = 2 # 클래스 수\n",
    "NUM_EPOCHS = 1 # epoch 수\n",
    "NUM_FILTERS = 32 # convolution 필터 수\n",
    "NUM_POOL = 2 # max plling을 위한 pooling 영역 크기\n",
    "NUM_CONV = 3 # convolution 커널 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 관련 환경설정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_CHANNELS = 1\n",
    "IMG_ROWS = 64\n",
    "IMG_COLS = 64\n",
    "\n",
    "TRAIN_DATA_COUNT = 447648\n",
    "\n",
    "train_img_filename = './datasets/train_image_64x64_gray_447648.bin'\n",
    "train_label_filename = './datasets/train_label_64x64_gray_447648.bin'\n",
    "\n",
    "TEST_DATA_COUNT = 15873\n",
    "\n",
    "test_img_filename = './datasets/test_image_64x64_gray_15873.bin'\n",
    "test_label_filename = './datasets/test_label_64x64_gray_15873.bin'\n",
    "\n",
    "VALIDATION_DATA_COUNT = int(TRAIN_DATA_COUNT * 1.0/4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_FILE_PATH = './seq_model_cnn.h5'\n",
    "PREDICT_FILE_PATH = './predict.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img 자료 로딩 함수 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(filename, count, channel, row, col):\n",
    "    print('Loading data from', filename)\n",
    "\n",
    "    print('file size : ', os.path.getsize(filename))\n",
    "    print('calc size : ', count * channel * row * col)\n",
    "    \n",
    "    fp = open(filename, 'rb')\n",
    "    buf = fp.read(count * channel * row * col)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8)\n",
    "    data = data.reshape(count, channel, row, col)\n",
    "\n",
    "    print('loaded shape : ', data.shape)\n",
    "\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label 자료 로딩함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_label(filename, count, classes):\n",
    "    print('Loading labels from ', filename)\n",
    "    \n",
    "    print('file size : ', os.path.getsize(filename))\n",
    "    print('calc size : ', count)\n",
    "    \n",
    "    fp = open(filename, 'r')\n",
    "    buf = fp.read(count)\n",
    "        \n",
    "    data_bin = []\n",
    "    for i in buf:\n",
    "        data_bin.append(i)\n",
    "    data = np.asarray(data_bin, dtype=np.uint8, order='C')\n",
    "\n",
    "    print('loaded shape : ', data.shape)\n",
    "    \n",
    "    label_hist = np.histogram(data, bins=range(NUM_CLASSES+1))\n",
    "    print(label_hist)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    data = np_utils.to_categorical(data, classes)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./datasets/train_image_64x64_gray_447648.bin\n",
      "file size :  1833566208\n",
      "calc size :  1833566208\n",
      "loaded shape :  (447648, 1, 64, 64)\n",
      "Loading data from ./datasets/test_image_64x64_gray_15873.bin\n",
      "file size :  65015808\n",
      "calc size :  65015808\n",
      "loaded shape :  (15873, 1, 64, 64)\n",
      "Loading labels from  ./datasets/train_label_64x64_gray_447648.bin\n",
      "file size :  447648\n",
      "calc size :  447648\n",
      "loaded shape :  (447648,)\n",
      "(array([354528,  93120]), array([0, 1, 2]))\n",
      "Loading labels from  ./datasets/test_label_64x64_gray_15873.bin\n",
      "file size :  15873\n",
      "calc size :  15873\n",
      "loaded shape :  (15873,)\n",
      "(array([15520,   353]), array([0, 1, 2]))\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "train_img = load_img(train_img_filename, TRAIN_DATA_COUNT, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "test_img = load_img(test_img_filename, TEST_DATA_COUNT, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "#validation_img = load_img(validation_img_filename, VALIDATION_DATA_COUNT, IMG_CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "\n",
    "train_label = load_label(train_label_filename, TRAIN_DATA_COUNT, NUM_CLASSES)\n",
    "test_label = load_label(test_label_filename, TEST_DATA_COUNT, NUM_CLASSES)\n",
    "#validation_label = load_label(validation_label_filename, VALIDATION_DATA_COUNT, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 일부로부터 검증셋을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count : 223824\n",
      "validation count : 111912\n"
     ]
    }
   ],
   "source": [
    "validation_img = train_img[:VALIDATION_DATA_COUNT, ...]\n",
    "validation_label = train_label[:VALIDATION_DATA_COUNT, ...]\n",
    "\n",
    "train_img = train_img[VALIDATION_DATA_COUNT:, ...]\n",
    "train_label = train_label[VALIDATION_DATA_COUNT:, ...]\n",
    "\n",
    "print('train count : ' + str(len(train_img)))\n",
    "print('validation count : ' + str(len(validation_img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥리닝 모델을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Convolution2D(NUM_FILTERS, NUM_CONV, NUM_CONV,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(IMG_CHANNELS, IMG_ROWS, IMG_COLS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(NUM_FILTERS, NUM_CONV, NUM_CONV))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(NUM_POOL, NUM_POOL)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# np_utils.visualize_util.plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 223824 samples, validate on 111912 samples\n",
      "Epoch 1/1\n",
      "223824/223824 [==============================] - 10736s - loss: 0.2083 - acc: 0.9125 - val_loss: 0.1512 - val_acc: 0.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126456710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_img, \n",
    "          train_label, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          nb_epoch=NUM_EPOCHS,\n",
    "          verbose=1, \n",
    "          validation_data=(validation_img, validation_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델 테스트를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15873/15873 [==============================] - 4s     \n",
      "Test score: 0.0604064624439\n",
      "Test accuracy: 0.97668997669\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_img, test_label, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15873/15873 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "classes = model.predict_classes(test_img, batch_size=32)\n",
    "np.savetxt(PREDICT_FILE_PATH, classes, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)    (None, 32, 62, 62)  320         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)          (None, 32, 62, 62)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)    (None, 32, 60, 60)  9248        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)          (None, 32, 60, 60)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)      (None, 32, 30, 30)  0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 32, 30, 30)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                (None, 28800)       0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 128)         3686528     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)          (None, 128)         0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 128)         0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 2)           258         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 2)           0           dense_2[0][0]                    "
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save_weights(MODEL_SAVE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
