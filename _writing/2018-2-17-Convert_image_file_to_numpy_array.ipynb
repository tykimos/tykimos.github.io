{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"이미지 파일에서 numpy 배열 만들기\"\n",
    "author: 홍소망\n",
    "date:   2018-2-17 04:00:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: https://i.imgur.com/ukIjVMM.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 예제로 가장 먼저 하는 것이 MNIST 분류문제를 하는 것일껍니다. 케라스에서는 MNIST 데이터셋을 코드 한 줄로 쉽게 로딩을 할 수 있습니다만, 파이썬을 처음 시작하시는 분이 막상 자기의 이미지 파일을 로딩하려면 막막할 때가 있습니다. 그래서 이번에는 MNIST 데이터셋을 이미지 파일로 만들어보고, 만든 이미지 파일을 다시 numpy array로 복원하는 연습을 해보면서, 이미지 파일을 자유롭게 다루는 법을 익히고자 합니다. 저희회사((주)인스페이스)에서 대덕소프트웨어마이스터고 인턴쉽 과정으로 함께하고 있는 홍소망 인턴님이 작성해주셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 주요 함수 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy 배열을 이미지로 저장하기\n",
    "\n",
    "설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 파일에서 numpy 배열로 복원하기\n",
    "\n",
    "설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 연습 순서\n",
    "\n",
    "* MNIST 데이터셋으로 분류하기\n",
    "* MNIST 데이터셋을 이미지 파일로 저장하기\n",
    "* 이미지 파일에서 numpy 배열로 만든 MNIST 데이터셋으로 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST 데이터셋으로 분류하기\n",
    "\n",
    "설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST 데이터셋을 이미지 파일로 저장하기\n",
    "\n",
    "설명\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 파일에서 numpy 배열로 만든 MNIST 데이터셋으로 분류하기\n",
    "\n",
    "설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 요약\n",
    "\n",
    "설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist을 이미지로 변환하고, 변환한 이미지를 numpy로 다시 변환하여 학습시킨 결과와 mnist의 학습결과를 비교해 보겠습니다. 다음과 같은 순서로 진행하겠습니다.\n",
    "\n",
    "1.mnist를 이미지로 변환하기\n",
    "\n",
    "2.이미지를 numpy로변환하기\n",
    "\n",
    "3.학습시키기\n",
    "\n",
    "4.mnist와 이미지 학습결과 비교하기\n",
    "\n",
    "\n",
    "\n",
    "##1.mnist를 이미지로 변환하기\n",
    "\n",
    "mnistsms 아래와 같이 손으로 쓰여진 이미지로 되어있습니다.\n",
    "<img src='https://i.imgur.com/HIQ6FNQ.png' >\n",
    "<img src='https://i.imgur.com/8HgRgz3.png'>\n",
    "\n",
    "먼저 mnist를 이미지로 변환 해주기 위해서 아래와 같이 import를 해줍니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\venv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음 mnist 데이터셋을 로드해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "import numpy as n\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(np.shape(X_train)[0]): #60000\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    path=\"D:/deeplearning1/mnist/\"+str(i)+\".png\"\n",
    "    imsave(path,X_test[i])\n",
    "\n",
    "for i in range(np.shape(X_test)[0]): #10000\n",
    "    plt.imshow(X_test[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    path=\"D:/deeplearning2/mnist/\"+str(i)+\".png\"\n",
    "    imsave(path,X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지가 잘 나오는지 보기 위해 plt.imshow()를 해줬습니다. \n",
    "\n",
    "imsave를 통해 해당 path에 저장됩니다.\n",
    "\n",
    "결과를 보면 아래처럼 총 70000개가  저장이 되어있습니다.\n",
    "<img src='https://i.imgur.com/tf5bncz.png' width='400' height='200' >\n",
    "<img src='https://i.imgur.com/cf2QZaP.png' width='400' height='300'>\n",
    "##2.이미지를 numpy로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as pilimg\n",
    "train=[]\n",
    "test=[]\n",
    "for i in range(60000):\n",
    "    train_generator = pilimg.open('D:deeplearning/mnist/'+str(i)+'.png')\n",
    "    train1 = np.array(train_generator) #이미지를 배열로 변환한 부분\n",
    "    print('train1:',train1)\n",
    "    train.append(train1)               #이미지를 배열에 넣은 것을 하나의 배열에 넣는 부분\n",
    "print(\"np.shape(train):\",np.shape(train))\n",
    "\n",
    "for i in range(10000):\n",
    "    test_generator = pilimg.open('D:deeplearning2/mnist/'+str(i)+'.png')\n",
    "    test1=np.array( test_generator)\n",
    "    print('test1:',test1)\n",
    "    test.append(test1)\n",
    "print(\"np.shape\",np.shape(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑에 사진은 하나의  이미지를 배열로 변환한 것입니다.\n",
    "<img src=\"https://i.imgur.com/ukIjVMM.png\">\n",
    "이미지를 배열로 변환한 것을 한 배열 안에 넣어주면, [[[]]]이런 모양의 3차원 배열이 됩니다.\n",
    "train의shape는 (60000, 28, 28)이 되고, test의 shape는 (10000.28,28)이 됩니다.\n",
    "\n",
    "##3.학습시키기\n",
    "numpy로 변환한것을 학습시키기 전에 mnist 예제에서 데이터셋 부분만 이미지를 numpy로 바꿔준 코드로 바꿔줍니다.\n",
    "mnist예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "dfdf (60000, 10)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 300s 5ms/step - loss: 0.2696 - acc: 0.9168 - val_loss: 0.0593 - val_acc: 0.9811\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0859 - acc: 0.9749 - val_loss: 0.0401 - val_acc: 0.9864\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 311s 5ms/step - loss: 0.0644 - acc: 0.9813 - val_loss: 0.0344 - val_acc: 0.9884\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0538 - acc: 0.9835 - val_loss: 0.0318 - val_acc: 0.9893\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0468 - acc: 0.9855 - val_loss: 0.0319 - val_acc: 0.9889\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 264s 4ms/step - loss: 0.0424 - acc: 0.9873 - val_loss: 0.0282 - val_acc: 0.9902\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 266s 4ms/step - loss: 0.0364 - acc: 0.9890 - val_loss: 0.0297 - val_acc: 0.9894\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 275s 5ms/step - loss: 0.0332 - acc: 0.9898 - val_loss: 0.0281 - val_acc: 0.9910\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 282s 5ms/step - loss: 0.0303 - acc: 0.9907 - val_loss: 0.0274 - val_acc: 0.9912\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0278 - acc: 0.9918 - val_loss: 0.0252 - val_acc: 0.9920\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 271s 5ms/step - loss: 0.0282 - acc: 0.9916 - val_loss: 0.0254 - val_acc: 0.9921\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 263s 4ms/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.0286 - val_acc: 0.9911\n",
      "Test loss: 0.02859834259810159\n",
      "Test accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('dfdf',y_train.shape)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바뀐코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(train): (60000, 28, 28)\n",
      "np.shape (10000, 28, 28)\n",
      "train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "dfdf (60000, 10)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 268s 4ms/step - loss: 0.2726 - acc: 0.9143 - val_loss: 0.0592 - val_acc: 0.9806\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 260s 4ms/step - loss: 0.0886 - acc: 0.9740 - val_loss: 0.0383 - val_acc: 0.9873\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 264s 4ms/step - loss: 0.0635 - acc: 0.9806 - val_loss: 0.0348 - val_acc: 0.9884\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 282s 5ms/step - loss: 0.0550 - acc: 0.9831 - val_loss: 0.0317 - val_acc: 0.9891\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0457 - acc: 0.9859 - val_loss: 0.0337 - val_acc: 0.9890\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 262s 4ms/step - loss: 0.0403 - acc: 0.9882 - val_loss: 0.0260 - val_acc: 0.9922\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0354 - acc: 0.9889 - val_loss: 0.0312 - val_acc: 0.9909\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 264s 4ms/step - loss: 0.0326 - acc: 0.9901 - val_loss: 0.0273 - val_acc: 0.9905\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 262s 4ms/step - loss: 0.0302 - acc: 0.9905 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 280s 5ms/step - loss: 0.0275 - acc: 0.9917 - val_loss: 0.0294 - val_acc: 0.9912\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 259s 4ms/step - loss: 0.0265 - acc: 0.9923 - val_loss: 0.0269 - val_acc: 0.9917\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0254 - acc: 0.9922 - val_loss: 0.0283 - val_acc: 0.9915\n",
      "Test loss: 0.028318152202017517\n",
      "Test accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import PIL.Image as pilimg\n",
    "\n",
    "train=[]\n",
    "test=[]\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\t#y_train과 y_test를 사용하기위해서\n",
    "\n",
    "for i in range(60000):\n",
    "    train_generator = pilimg.open('D:deeplearningtest/mnist/'+str(i)+'.png')\n",
    "    train1 = np.array(train_generator) #이미지를 배열로 변환한 부분\n",
    "#    print('train1:',train1)\n",
    "    train.append(train1)\t\t\t  #이미지를 배열에 넣은 것을 하나의 배열에 넣는 부분\n",
    "print(\"np.shape(train):\",np.shape(train))\n",
    "\n",
    "for i in range(10000):\n",
    "    test_generator = pilimg.open('D:deeplearning2/mnist/'+str(i)+'.png')\n",
    "    test1=np.array( test_generator)\n",
    " #   print('test1:',test1)\n",
    "    test.append(test1)\n",
    "print(\"np.shape\",np.shape(test))\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    train = np.reshape(train,(np.shape(train)[0], 1, img_rows, img_cols))\n",
    "    test = np.reshape(test,(np.shape(test)[0], 1, img_rows, img_cols))\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    train = np.reshape(train,(np.shape(train)[0], img_rows, img_cols, 1))\n",
    "    test = np.reshape(test,(np.shape(test)[0], img_rows, img_cols, 1))\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "train = train.astype('float32')\n",
    "test = test.astype('float32')\n",
    "train /= 255\n",
    "test /= 255\n",
    "print('train shape:',np.shape(train))\n",
    "print(np.shape(train)[0], 'train samples')\n",
    "print(np.shape(test)[0], 'test samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('dfdf',y_train.shape)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test, y_test))\n",
    "score = model.evaluate(test, y_test, verbose=0)\n",
    "\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y값들은 사진에 나와있는 숫자들인데 총 7만개를 만들 수 없어서 mnist에 있는 것을 사용하였습니다.\n",
    "\n",
    "그리고 train.shape -> np.shape(train)\n",
    "       test.shape -> np.shape(test)\n",
    "\t   train.reshape()->np.reshape(train,()) \n",
    "\t   test.reshape()->np.reshape(test,()) 로 바꿔줍니다.\n",
    "\n",
    "바꿔주지 않는다면 AttributeError:'list' object has no attribute 'shape' 에러가 납니다.\n",
    "\n",
    "##4.mnist와 이미지 학습결과 비교하기\n",
    "\n",
    "mnist와 이미지의 학습결과를 비교하겠습니다.\n",
    "\n",
    "mnist의 학습결과는 0.9911이고, 이미지의 학습결과는 0.9915입니다.\n",
    "이미지 학습 결과가  0.0004만큼 높지만, 거의 비슷하다고 할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
